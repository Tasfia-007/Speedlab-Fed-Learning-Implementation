{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":670237,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":507599,"modelId":522298}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ============================================================================\n# COMPLETE STANDALONE ATTACK EVALUATION - SINGLE CELL (WITH EXTENDED METRICS)\n# ============================================================================\nprint(\"Installing dependencies...\")\nimport subprocess\nimport os\n\n# Install\nsubprocess.run([\"pip\", \"install\", \"medmnist\", \"--quiet\"], check=True)\nsubprocess.run([\"pip\", \"install\", \"git+https://github.com/openai/CLIP.git\", \"--quiet\"], check=True)\nsubprocess.run([\"pip\", \"install\", \"scikit-learn\", \"--quiet\"], check=True)\n\n# Now import everything\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms\nfrom medmnist.dataset import PathMNIST, TissueMNIST, OrganAMNIST, OCTMNIST\nimport clip\nfrom tqdm import tqdm\nimport json\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.metrics import precision_score, recall_score, f1_score, mean_squared_error\n\nprint(\"✅ All dependencies loaded!\")\n\n# ========================================\n# CONFIGURATION - CHANGE THESE\n# ========================================\nMODEL_PATH = \"/kaggle/input/example/pytorch/default/1/Example/checkpoints_fedavg_organamnist/final_global_model.pth\"\nDATASET_NAME = \"organamnist\"\nBATCH_SIZE = 32\nSAVE_DIR = \"/kaggle/working/attack_results\"\n# ========================================\n\nos.makedirs('./data/medmnist', exist_ok=True)\nos.makedirs(SAVE_DIR, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Dataset configs\nDATASET_CONFIGS = {\n    'pathmnist': {\n        'num_classes': 9,\n        'class': PathMNIST,\n        'class_names': [\"adipose\", \"background\", \"debris\", \"lymphocytes\",\n                       \"mucus\", \"smooth muscle\", \"normal colon mucosa\",\n                       \"cancer-associated stroma\", \"colorectal adenocarcinoma epithelium\"]\n    },\n    'tissuemnist': {\n        'num_classes': 8,\n        'class': TissueMNIST,\n        'class_names': [\"collecting duct\", \"thick ascending limb\",\n                       \"distal convoluted tubule\", \"proximal tubule\",\n                       \"glomerular tuft\", \"blood vessel\", \"macula densa\",\n                       \"interstitial fibrosis\"]\n    },\n    'organamnist': {\n        'num_classes': 11,\n        'class': OrganAMNIST,\n        'class_names': [\"bladder\", \"femur-left\", \"femur-right\", \"heart\",\n                       \"kidneys\", \"liver\", \"lungs\", \"pancreas\",\n                       \"pelvis\", \"spleen\", \"kidney cyst\"]\n    },\n    'octmnist': {\n        'num_classes': 4,\n        'class': OCTMNIST,\n        'class_names': [\"choroidal neovascularization\", \"diabetic macular edema\",\n                       \"drusen\", \"normal\"]\n    }\n}\n\n# Model class\nclass CLIPMedMNISTClassifier(nn.Module):\n    def __init__(self, num_classes, device, class_names=None):\n        super(CLIPMedMNISTClassifier, self).__init__()\n        self.clip_model, _ = clip.load(\"ViT-B/32\", device=device)\n        self.num_classes = num_classes\n        \n        for param in self.clip_model.transformer.parameters():\n            param.requires_grad = False\n        for param in self.clip_model.token_embedding.parameters():\n            param.requires_grad = False\n        for param in self.clip_model.ln_final.parameters():\n            param.requires_grad = False\n        self.clip_model.positional_embedding.requires_grad = False\n        self.clip_model.text_projection.requires_grad = False\n        \n        if class_names:\n            with torch.no_grad():\n                text_tokens = clip.tokenize([f\"a microscopic image of {c}\" for c in class_names]).to(device)\n                text_features = self.clip_model.encode_text(text_tokens)\n                text_features /= text_features.norm(dim=-1, keepdim=True)\n            self.register_buffer('text_features', text_features)\n    \n    def forward(self, images):\n        image_features = self.clip_model.encode_image(images)\n        image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n        return 100.0 * image_features @ self.text_features.T\n\n# Attack functions\ndef fgsm(model, x, y, device, eps=0.03):\n    x = x.clone().detach().requires_grad_(True)\n    out = model(x)\n    out = out.logits if hasattr(out, 'logits') else out\n    loss = F.cross_entropy(out, y)\n    loss.backward()\n    return torch.clamp(x + eps * x.grad.sign(), -1, 1).detach()\n\ndef pgd(model, x, y, device, eps=0.03, alpha=0.01, steps=10):\n    x_adv = x + torch.empty_like(x).uniform_(-eps, eps)\n    x_adv = torch.clamp(x_adv, -1, 1)\n    for _ in range(steps):\n        x_adv.requires_grad_(True)\n        out = model(x_adv)\n        out = out.logits if hasattr(out, 'logits') else out\n        loss = F.cross_entropy(out, y)\n        loss.backward()\n        x_adv = x_adv.detach() + alpha * x_adv.grad.sign()\n        x_adv = torch.clamp(x_adv, x - eps, x + eps)\n        x_adv = torch.clamp(x_adv, -1, 1)\n    return x_adv.detach()\n\ndef bim(model, x, y, device, eps=0.03, alpha=0.01, steps=10):\n    x_adv = x.clone()\n    for _ in range(steps):\n        x_adv.requires_grad_(True)\n        out = model(x_adv)\n        out = out.logits if hasattr(out, 'logits') else out\n        loss = F.cross_entropy(out, y)\n        loss.backward()\n        x_adv = x_adv.detach() + alpha * x_adv.grad.sign()\n        x_adv = torch.clamp(x_adv, x - eps, x + eps)\n        x_adv = torch.clamp(x_adv, -1, 1)\n    return x_adv.detach()\n\ndef mifgsm(model, x, y, device, eps=0.03, alpha=0.01, steps=10, decay=1.0):\n    momentum = torch.zeros_like(x).to(device)\n    x_adv = x.clone()\n    for _ in range(steps):\n        x_adv.requires_grad_(True)\n        out = model(x_adv)\n        out = out.logits if hasattr(out, 'logits') else out\n        loss = F.cross_entropy(out, y)\n        loss.backward()\n        grad = x_adv.grad.data\n        grad = grad / (torch.mean(torch.abs(grad), dim=(1,2,3), keepdim=True) + 1e-8)\n        momentum = decay * momentum + grad\n        x_adv = x_adv.detach() + alpha * momentum.sign()\n        x_adv = torch.clamp(x_adv, x - eps, x + eps)\n        x_adv = torch.clamp(x_adv, -1, 1)\n    return x_adv.detach()\n\ndef deepfool(model, x, y, device, steps=30):\n    perturbed = x.clone()\n    for idx in range(x.size(0)):\n        img = x[idx:idx+1].clone()\n        pert = img.clone()\n        for _ in range(steps):\n            pert.requires_grad_(True)\n            out = model(pert)\n            out = out.logits if hasattr(out, 'logits') else out\n            pred = out.max(1)[1].item()\n            if pred != y[idx].item():\n                break\n            model.zero_grad()\n            out[0, pred].backward(retain_graph=True)\n            grad_pred = pert.grad.data.clone()\n            min_dist, min_grad = 1e10, None\n            for k in range(out.size(1)):\n                if k == pred:\n                    continue\n                model.zero_grad()\n                pert.grad = None\n                try:\n                    out[0, k].backward(retain_graph=True)\n                    grad_k = pert.grad.data.clone()\n                    w_k = grad_k - grad_pred\n                    f_k = out[0, k] - out[0, pred]\n                    dist = abs(f_k.item()) / (torch.norm(w_k.flatten()).item() + 1e-8)\n                    if dist < min_dist:\n                        min_dist, min_grad = dist, w_k\n                except:\n                    continue\n            if min_grad is not None:\n                r = (min_dist + 1e-4) * min_grad / (torch.norm(min_grad.flatten()) + 1e-8)\n                pert = torch.clamp(pert.detach() + 1.02 * r, -1, 1)\n            else:\n                break\n        perturbed[idx:idx+1] = pert.detach()\n    return perturbed\n\n# Load data\nprint(f\"\\n{'='*70}\")\nprint(\" LOADING DATA\")\nprint('='*70)\nconfig = DATASET_CONFIGS[DATASET_NAME.lower()]\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.Grayscale(num_output_channels=3),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n])\ntest_dataset = config['class'](root='./data/medmnist', split='test', download=True, transform=transform)\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\nprint(f\"✅ Loaded {len(test_dataset)} test samples | Classes: {config['num_classes']}\")\n\n# Load model\nprint(f\"\\n{'='*70}\")\nprint(\" LOADING MODEL\")\nprint('='*70)\nmodel = CLIPMedMNISTClassifier(config['num_classes'], device, config['class_names'])\ncheckpoint = torch.load(MODEL_PATH, map_location=device)\nif isinstance(checkpoint, dict):\n    if 'server_state_dict' in checkpoint:\n        model.load_state_dict(checkpoint['server_state_dict'])\n    elif 'model_state_dict' in checkpoint:\n        model.load_state_dict(checkpoint['model_state_dict'])\n    else:\n        model.load_state_dict(checkpoint)\nelse:\n    model.load_state_dict(checkpoint)\nmodel.eval()\nprint(\"✅ Model loaded successfully\")\n\n# Run attacks\nprint(f\"\\n{'='*70}\")\nprint(\" RUNNING 5 ATTACKS WITH EXTENDED METRICS\")\nprint('='*70)\n\nattacks = {\n    'FGSM': lambda x, y: fgsm(model, x, y, device),\n    'PGD': lambda x, y: pgd(model, x, y, device),\n    'BIM': lambda x, y: bim(model, x, y, device),\n    'MI-FGSM': lambda x, y: mifgsm(model, x, y, device),\n    'DeepFool': lambda x, y: deepfool(model, x, y, device)\n}\n\nresults = []\nfor name, attack_fn in attacks.items():\n    print(f\"\\n[{name}]\")\n    \n    # Storage for predictions and labels\n    clean_preds, clean_labels = [], []\n    adv_preds, adv_labels = [], []\n    clean_probs, adv_probs = [], []\n    \n    for imgs, lbls in tqdm(test_loader, desc=f\"  {name:12s}\", ncols=100, leave=False):\n        imgs, lbls = imgs.to(device), lbls.to(device).squeeze()\n        \n        # Clean predictions\n        with torch.no_grad():\n            out = model(imgs)\n            probs = F.softmax(out, dim=1)\n            preds = out.max(1)[1]\n            \n            clean_preds.extend(preds.cpu().numpy())\n            clean_labels.extend(lbls.cpu().numpy())\n            clean_probs.extend(probs.cpu().numpy())\n        \n        # Adversarial predictions\n        try:\n            adv = attack_fn(imgs, lbls)\n            with torch.no_grad():\n                out = model(adv)\n                probs = F.softmax(out, dim=1)\n                preds = out.max(1)[1]\n                \n                adv_preds.extend(preds.cpu().numpy())\n                adv_labels.extend(lbls.cpu().numpy())\n                adv_probs.extend(probs.cpu().numpy())\n        except:\n            # If attack fails, use clean predictions\n            adv_preds.extend(clean_preds[-len(lbls):])\n            adv_labels.extend(lbls.cpu().numpy())\n            adv_probs.extend(clean_probs[-len(lbls):])\n    \n    # Convert to numpy\n    clean_preds = np.array(clean_preds)\n    clean_labels = np.array(clean_labels)\n    adv_preds = np.array(adv_preds)\n    adv_labels = np.array(adv_labels)\n    clean_probs = np.array(clean_probs)\n    adv_probs = np.array(adv_probs)\n    \n    # Calculate metrics for clean\n    clean_acc = 100 * (clean_preds == clean_labels).mean()\n    clean_prec = 100 * precision_score(clean_labels, clean_preds, average='weighted', zero_division=0)\n    clean_rec = 100 * recall_score(clean_labels, clean_preds, average='weighted', zero_division=0)\n    clean_f1 = 100 * f1_score(clean_labels, clean_preds, average='weighted', zero_division=0)\n    \n    # Calculate metrics for adversarial\n    adv_acc = 100 * (adv_preds == adv_labels).mean()\n    adv_prec = 100 * precision_score(adv_labels, adv_preds, average='weighted', zero_division=0)\n    adv_rec = 100 * recall_score(adv_labels, adv_preds, average='weighted', zero_division=0)\n    adv_f1 = 100 * f1_score(adv_labels, adv_preds, average='weighted', zero_division=0)\n    \n    # Calculate RMSE (on probabilities)\n    clean_rmse = np.sqrt(mean_squared_error(\n        np.eye(config['num_classes'])[clean_labels], clean_probs\n    ))\n    adv_rmse = np.sqrt(mean_squared_error(\n        np.eye(config['num_classes'])[adv_labels], adv_probs\n    ))\n    \n    # Attack Success Rate\n    asr = 100 * (clean_preds != adv_preds).mean()\n    \n    print(f\"  CLEAN METRICS:\")\n    print(f\"    Accuracy:  {clean_acc:.2f}%\")\n    print(f\"    Precision: {clean_prec:.2f}%\")\n    print(f\"    Recall:    {clean_rec:.2f}%\")\n    print(f\"    F1-Score:  {clean_f1:.2f}%\")\n    print(f\"    RMSE:      {clean_rmse:.4f}\")\n    print(f\"  ADVERSARIAL METRICS:\")\n    print(f\"    Accuracy:  {adv_acc:.2f}%\")\n    print(f\"    Precision: {adv_prec:.2f}%\")\n    print(f\"    Recall:    {adv_rec:.2f}%\")\n    print(f\"    F1-Score:  {adv_f1:.2f}%\")\n    print(f\"    RMSE:      {adv_rmse:.4f}\")\n    print(f\"  ASR: {asr:.2f}%\")\n    \n    results.append({\n        'attack': name,\n        'clean_metrics': {\n            'accuracy': round(clean_acc, 2),\n            'precision': round(clean_prec, 2),\n            'recall': round(clean_rec, 2),\n            'f1_score': round(clean_f1, 2),\n            'rmse': round(clean_rmse, 4)\n        },\n        'adversarial_metrics': {\n            'accuracy': round(adv_acc, 2),\n            'precision': round(adv_prec, 2),\n            'recall': round(adv_rec, 2),\n            'f1_score': round(adv_f1, 2),\n            'rmse': round(adv_rmse, 4)\n        },\n        'attack_success_rate': round(asr, 2)\n    })\n\n# Save results\nwith open(f\"{SAVE_DIR}/attack_results_extended.json\", 'w') as f:\n    json.dump(results, f, indent=2)\n\n# Create comprehensive visualization\nfig = plt.figure(figsize=(18, 10))\ngs = fig.add_gridspec(2, 3, hspace=0.3, wspace=0.3)\n\nnames = [r['attack'] for r in results]\nx = np.arange(len(names))\n\n# Plot 1: Accuracy\nax1 = fig.add_subplot(gs[0, 0])\nclean_acc = [r['clean_metrics']['accuracy'] for r in results]\nadv_acc = [r['adversarial_metrics']['accuracy'] for r in results]\nax1.bar(x - 0.2, clean_acc, 0.4, label='Clean', alpha=0.8, color='#2ecc71')\nax1.bar(x + 0.2, adv_acc, 0.4, label='Adversarial', alpha=0.8, color='#e74c3c')\nax1.set_ylabel('Accuracy (%)'); ax1.set_title('Accuracy Comparison', fontweight='bold')\nax1.set_xticks(x); ax1.set_xticklabels(names, rotation=15)\nax1.legend(); ax1.grid(alpha=0.3, axis='y')\n\n# Plot 2: Precision\nax2 = fig.add_subplot(gs[0, 1])\nclean_prec = [r['clean_metrics']['precision'] for r in results]\nadv_prec = [r['adversarial_metrics']['precision'] for r in results]\nax2.bar(x - 0.2, clean_prec, 0.4, label='Clean', alpha=0.8, color='#3498db')\nax2.bar(x + 0.2, adv_prec, 0.4, label='Adversarial', alpha=0.8, color='#e67e22')\nax2.set_ylabel('Precision (%)'); ax2.set_title('Precision Comparison', fontweight='bold')\nax2.set_xticks(x); ax2.set_xticklabels(names, rotation=15)\nax2.legend(); ax2.grid(alpha=0.3, axis='y')\n\n# Plot 3: Recall\nax3 = fig.add_subplot(gs[0, 2])\nclean_rec = [r['clean_metrics']['recall'] for r in results]\nadv_rec = [r['adversarial_metrics']['recall'] for r in results]\nax3.bar(x - 0.2, clean_rec, 0.4, label='Clean', alpha=0.8, color='#9b59b6')\nax3.bar(x + 0.2, adv_rec, 0.4, label='Adversarial', alpha=0.8, color='#34495e')\nax3.set_ylabel('Recall (%)'); ax3.set_title('Recall Comparison', fontweight='bold')\nax3.set_xticks(x); ax3.set_xticklabels(names, rotation=15)\nax3.legend(); ax3.grid(alpha=0.3, axis='y')\n\n# Plot 4: F1 Score\nax4 = fig.add_subplot(gs[1, 0])\nclean_f1 = [r['clean_metrics']['f1_score'] for r in results]\nadv_f1 = [r['adversarial_metrics']['f1_score'] for r in results]\nax4.bar(x - 0.2, clean_f1, 0.4, label='Clean', alpha=0.8, color='#1abc9c')\nax4.bar(x + 0.2, adv_f1, 0.4, label='Adversarial', alpha=0.8, color='#c0392b')\nax4.set_ylabel('F1-Score (%)'); ax4.set_title('F1-Score Comparison', fontweight='bold')\nax4.set_xticks(x); ax4.set_xticklabels(names, rotation=15)\nax4.legend(); ax4.grid(alpha=0.3, axis='y')\n\n# Plot 5: RMSE\nax5 = fig.add_subplot(gs[1, 1])\nclean_rmse = [r['clean_metrics']['rmse'] for r in results]\nadv_rmse = [r['adversarial_metrics']['rmse'] for r in results]\nax5.bar(x - 0.2, clean_rmse, 0.4, label='Clean', alpha=0.8, color='#f39c12')\nax5.bar(x + 0.2, adv_rmse, 0.4, label='Adversarial', alpha=0.8, color='#d35400')\nax5.set_ylabel('RMSE'); ax5.set_title('RMSE Comparison', fontweight='bold')\nax5.set_xticks(x); ax5.set_xticklabels(names, rotation=15)\nax5.legend(); ax5.grid(alpha=0.3, axis='y')\n\n# Plot 6: Attack Success Rate\nax6 = fig.add_subplot(gs[1, 2])\nasr = [r['attack_success_rate'] for r in results]\ncolors = ['#e74c3c', '#e67e22', '#f39c12', '#d35400', '#c0392b']\nax6.bar(names, asr, color=colors, alpha=0.8)\nax6.set_ylabel('ASR (%)'); ax6.set_title('Attack Success Rate', fontweight='bold')\nax6.set_xticklabels(names, rotation=15); ax6.grid(alpha=0.3, axis='y')\n\nplt.savefig(f\"{SAVE_DIR}/attack_results_extended.png\", dpi=300, bbox_inches='tight')\nplt.close()\n\n# Print summary table\nprint(f\"\\n{'='*70}\")\nprint(\" COMPLETE! - DETAILED RESULTS\")\nprint('='*70)\nprint(f\"✅ JSON: {SAVE_DIR}/attack_results_extended.json\")\nprint(f\"✅ Plot: {SAVE_DIR}/attack_results_extended.png\")\nprint(f\"\\n{'='*120}\")\nprint(f\"{'Attack':<12} | {'Clean Acc':>9} | {'Adv Acc':>9} | {'Clean Prec':>10} | {'Adv Prec':>10} | {'Clean Rec':>10} | {'Adv Rec':>10} | {'Clean F1':>9} | {'Adv F1':>9} | {'ASR':>6}\")\nprint('='*120)\nfor r in results:\n    print(f\"{r['attack']:<12} | {r['clean_metrics']['accuracy']:>8.2f}% | {r['adversarial_metrics']['accuracy']:>8.2f}% | \"\n          f\"{r['clean_metrics']['precision']:>9.2f}% | {r['adversarial_metrics']['precision']:>9.2f}% | \"\n          f\"{r['clean_metrics']['recall']:>9.2f}% | {r['adversarial_metrics']['recall']:>9.2f}% | \"\n          f\"{r['clean_metrics']['f1_score']:>8.2f}% | {r['adversarial_metrics']['f1_score']:>8.2f}% | {r['attack_success_rate']:>5.2f}%\")\nprint('='*120)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T11:47:19.723523Z","iopub.execute_input":"2025-12-03T11:47:19.724371Z"}},"outputs":[{"name":"stdout","text":"Installing dependencies...\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 115.9/115.9 kB 4.3 MB/s eta 0:00:00\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 363.4/363.4 MB 5.2 MB/s eta 0:00:00\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 13.8/13.8 MB 119.4 MB/s eta 0:00:00\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 24.6/24.6 MB 93.6 MB/s eta 0:00:00\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 883.7/883.7 kB 48.1 MB/s eta 0:00:00\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 664.8/664.8 MB 2.8 MB/s eta 0:00:00\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 211.5/211.5 MB 8.7 MB/s eta 0:00:00\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 56.3/56.3 MB 35.2 MB/s eta 0:00:00\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 127.9/127.9 MB 15.0 MB/s eta 0:00:00\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 207.5/207.5 MB 7.8 MB/s eta 0:00:00\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 21.1/21.1 MB 9.4 MB/s eta 0:00:00\n","output_type":"stream"},{"name":"stderr","text":"ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\n","output_type":"stream"},{"name":"stdout","text":"   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 44.8/44.8 kB 1.7 MB/s eta 0:00:00\n✅ All dependencies loaded!\n\n======================================================================\n LOADING DATA\n======================================================================\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 38.2M/38.2M [00:09<00:00, 4.14MB/s]\n","output_type":"stream"},{"name":"stdout","text":"✅ Loaded 17778 test samples | Classes: 11\n\n======================================================================\n LOADING MODEL\n======================================================================\n","output_type":"stream"},{"name":"stderr","text":"100%|████████████████████████████████████████| 338M/338M [00:01<00:00, 315MiB/s]\n","output_type":"stream"},{"name":"stdout","text":"✅ Model loaded successfully\n\n======================================================================\n RUNNING 5 ATTACKS WITH EXTENDED METRICS\n======================================================================\n\n[FGSM]\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                    \r","output_type":"stream"},{"name":"stdout","text":"  CLEAN METRICS:\n    Accuracy:  90.12%\n    Precision: 90.20%\n    Recall:    90.12%\n    F1-Score:  89.95%\n    RMSE:      0.1210\n  ADVERSARIAL METRICS:\n    Accuracy:  56.25%\n    Precision: 54.72%\n    Recall:    56.25%\n    F1-Score:  54.64%\n    RMSE:      0.2759\n  ASR: 34.69%\n\n[PGD]\n","output_type":"stream"},{"name":"stderr","text":"  PGD         :   3%|█▏                                            | 14/556 [00:12<07:56,  1.14it/s]","output_type":"stream"}],"execution_count":null}]}