{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to Use This Version for Checkpoint Resume in Kaggle\n",
    "\n",
    "Before running this notebook for the second time (to resume training from a checkpoint), follow the steps below carefully.\n",
    "\n",
    "1. Download the latest checkpoint file\n",
    "Download the file named checkpoint_latest.pth from the previous version of your notebook or experiment.\n",
    "\n",
    "2. Upload the checkpoint to Kaggle Input Directory\n",
    "Place the downloaded file inside your Kaggle input path, for example:\n",
    "/kaggle/input/path1/pytorch/default/1/checkpoint_latest.pth\n",
    "\n",
    "3. Run the following code cell before starting training\n",
    "This code will copy the checkpoint file to the working directory (/kaggle/working/checkpoints) so that training can resume from the saved state.\n",
    "\n",
    "4. Resume Training\n",
    "After the checkpoint file is copied successfully, running the rest of the notebook will automatically start training from the previous checkpoint instead of starting from scratch.\n",
    "\n",
    "\n",
    "\n",
    "## you can change the dataset and the attack type by simply changing the name in the args.py file.no need to modify anything else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Source and destination paths\n",
    "src = \"/kaggle/input/path1/pytorch/default/1/checkpoint_latest.pth\"\n",
    "dst_dir = \"/kaggle/working/checkpoints\"\n",
    "dst = os.path.join(dst_dir, \"checkpoint_latest.pth\")\n",
    "\n",
    "# Step 1: Check if source file exists\n",
    "if not os.path.exists(src):\n",
    "    print(f\"âŒ Source file not found: {src}\")\n",
    "else:\n",
    "    print(f\"âœ… Found source file: {src}\")\n",
    "\n",
    "    # Step 2: Ensure destination directory exists\n",
    "    if not os.path.exists(dst_dir):\n",
    "        os.makedirs(dst_dir)\n",
    "        print(f\"ðŸ“‚ Created destination directory: {dst_dir}\")\n",
    "    else:\n",
    "        print(f\"ðŸ“ Destination directory already exists: {dst_dir}\")\n",
    "\n",
    "    # Step 3: Copy the file\n",
    "    shutil.copy(src, dst)\n",
    "    print(f\"âœ… Copied file to: {dst}\")\n",
    "\n",
    "    # Step 4: List all files in destination\n",
    "    files = os.listdir(dst_dir)\n",
    "    if files:\n",
    "        print(\"\\nðŸ“„ Files in /kaggle/working/checkpoints:\")\n",
    "        for f in files:\n",
    "            print(\" â”œâ”€â”€\", f)\n",
    "    else:\n",
    "        print(\"âš  Destination directory is empty (unexpected).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Target directory\n",
    "base_dir = \"/kaggle/working/FedBn-PyTorch\"\n",
    "os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "# Python files to create\n",
    "files = [\"main.py\", \"server.py\", \"client.py\", \"model.py\", \"get_data.py\", \"args.py\"]\n",
    "\n",
    "# Create each file if not exists\n",
    "for file in files:\n",
    "    file_path = os.path.join(base_dir, file)\n",
    "    if not os.path.exists(file_path):\n",
    "        with open(file_path, \"w\") as f:\n",
    "            f.write(f\"# {file} â€” auto-created placeholder\\n\")\n",
    "        print(f\" Created: {file_path}\")\n",
    "    else:\n",
    "        print(f\" Already exists: {file_path}\")\n",
    "\n",
    "print(\"\\n Folder and files ready in:\", base_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "file_path = \"/kaggle/working/FedBn-PyTorch/args.py\"\n",
    "\n",
    "new_code = '''\n",
    "# ========================================\n",
    "# args.py â€” FedBN Configuration \n",
    "# ========================================\n",
    "import argparse\n",
    "import torch\n",
    "\n",
    "DATASET_CONFIGS = {\n",
    "    'pathmnist': {'num_classes': 9, 'input_channels': 3},\n",
    "    'tissuemnist': {'num_classes': 8, 'input_channels': 1},\n",
    "    'organamnist': {'num_classes': 11, 'input_channels': 1},\n",
    "    'octmnist': {'num_classes': 4, 'input_channels': 1},\n",
    "}\n",
    "\n",
    "def args_parser():\n",
    "    parser = argparse.ArgumentParser(description=\"FedBN Config (4 Dataset Compatible)\")\n",
    "    \n",
    "    # -------------------------------\n",
    "    # Dataset\n",
    "    # -------------------------------\n",
    "    parser.add_argument('--dataset', type=str, default='organamnist',\n",
    "                        choices=['pathmnist', 'tissuemnist', 'organamnist', 'octmnist'],\n",
    "                        help='MedMNIST dataset to use')\n",
    "    parser.add_argument('--use_combined', action='store_true', \n",
    "                        help='Use train+val+test combined')\n",
    "\n",
    "    # -------------------------------\n",
    "    # Federated Learning Parameters\n",
    "    # -------------------------------\n",
    "    parser.add_argument('--E', type=int, default=5, help='local epochs')\n",
    "    parser.add_argument('--r', type=int, default=50, help='communication rounds')\n",
    "    parser.add_argument('--K', type=int, default=5, help='number of clients')\n",
    "    parser.add_argument('--C', type=float, default=1.0, help='client sampling rate')\n",
    "    parser.add_argument('--B', type=int, default=32, help='batch size')\n",
    "\n",
    "    # -------------------------------\n",
    "    # Model Parameters\n",
    "    # -------------------------------\n",
    "    parser.add_argument('--clip_model', type=str, default='ViT-B/32', help='CLIP model variant')\n",
    "    parser.add_argument('--freeze_clip', action='store_true', help='Freeze CLIP backbone')\n",
    "    parser.add_argument('--dropout', type=float, default=0.5, help='dropout rate')\n",
    "\n",
    "    # -------------------------------\n",
    "    # Optimizer Settings\n",
    "    # -------------------------------\n",
    "    parser.add_argument('--lr', type=float, default=0.003, help='learning rate')\n",
    "    parser.add_argument('--optimizer', type=str, default='sgd', help='optimizer type')\n",
    "    parser.add_argument('--weight_decay', type=float, default=5e-4, help='weight decay')\n",
    "    parser.add_argument('--momentum', type=float, default=0.9, help='momentum for SGD')\n",
    "\n",
    "    # -------------------------------\n",
    "    # FedBN Specific\n",
    "    # -------------------------------\n",
    "    parser.add_argument('--exclude_bn_from_agg', action='store_true',\n",
    "                        help='Exclude BN params from aggregation')\n",
    "    parser.add_argument('--freeze_bn', action='store_true', help='Freeze BN layers')\n",
    "    \n",
    "    # -------------------------------\n",
    "    # Others\n",
    "    # -------------------------------\n",
    "    parser.add_argument('--checkpoint_dir', type=str, default='./checkpoints_fedbn_organamnist')\n",
    "    parser.add_argument('--device', default=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "    parser.add_argument('--dominant_ratio', type=float, default=0.7, help='dominant ratio for Non-IID split')\n",
    "\n",
    "\n",
    "    # -------------------------------\n",
    "    # Adversarial Attack Parameters\n",
    "    # -------------------------------\n",
    "    parser.add_argument('--attack_type', type=str, default='none', \n",
    "                        choices=['none', 'fgsm', 'pgd', 'cw'],\n",
    "                        help='Type of adversarial attack during testing')\n",
    "    parser.add_argument('--attack_epsilon', type=float, default=0.06,  # Increased for [-1,1] range\n",
    "                    help='Epsilon for FGSM/PGD attacks')\n",
    "    parser.add_argument('--pgd_alpha', type=float, default=0.006,  # epsilon/10\n",
    "                        help='Step size for PGD')\n",
    "    parser.add_argument('--pgd_iters', type=int, default=10,\n",
    "                        help='Number of PGD iterations')\n",
    "    parser.add_argument('--cw_c', type=float, default=1.0,\n",
    "                        help='C parameter for CW attack')\n",
    "    parser.add_argument('--cw_max_iter', type=int, default=100,\n",
    "                        help='Max iterations for CW attack')\n",
    "\n",
    "    args = parser.parse_args(args=[])\n",
    "\n",
    "    if args.dataset in DATASET_CONFIGS:\n",
    "        cfg = DATASET_CONFIGS[args.dataset]\n",
    "        args.num_classes = cfg['num_classes']\n",
    "        args.input_channels = cfg['input_channels']\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported dataset {args.dataset}\")\n",
    "\n",
    "    return args\n",
    "\n",
    "'''\n",
    "\n",
    "with open(file_path, \"w\") as f:\n",
    "    f.write(new_code)\n",
    "\n",
    "print(\" args.py written successfully!\")\n",
    "print(f\" File path: {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "file_path = \"/kaggle/working/FedBn-PyTorch/get_data.py\"\n",
    "\n",
    "new_code = r'''\n",
    "# ========================================\n",
    "# get_data.py â€” Balanced Non-IID Loader (4 Dataset Compatible)\n",
    "# ========================================\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "from torch.utils.data import DataLoader, Subset, ConcatDataset\n",
    "from torchvision import transforms\n",
    "from medmnist.dataset import PathMNIST, TissueMNIST, OrganAMNIST, OCTMNIST\n",
    "\n",
    "DATASET_MAP = {\n",
    "    'pathmnist': PathMNIST,\n",
    "    'tissuemnist': TissueMNIST,\n",
    "    'organamnist': OrganAMNIST,\n",
    "    'octmnist': OCTMNIST,\n",
    "}\n",
    "\n",
    "def get_transforms():\n",
    "    \"\"\"Unified transforms (grayscale â†’ RGB for CLIP)\"\"\"\n",
    "    train_t = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.Grayscale(num_output_channels=3),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)\n",
    "    ])\n",
    "    test_t = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.Grayscale(num_output_channels=3),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)\n",
    "    ])\n",
    "    return train_t, test_t\n",
    "\n",
    "def balanced_noniid_split(dataset, num_clients, dominant_ratio=0.7):\n",
    "    labels = np.array([dataset[i][1].item() for i in range(len(dataset))])\n",
    "    n_classes = len(np.unique(labels))\n",
    "    client_indices = [[] for _ in range(num_clients)]\n",
    "\n",
    "    class_indices = {c: np.where(labels == c)[0].tolist() for c in range(n_classes)}\n",
    "    for c in class_indices: np.random.shuffle(class_indices[c])\n",
    "\n",
    "    for client_id in range(num_clients):\n",
    "        dom_class = client_id % n_classes\n",
    "        n_dom = int(len(class_indices[dom_class]) * dominant_ratio)\n",
    "        client_indices[client_id].extend(class_indices[dom_class][:n_dom])\n",
    "        class_indices[dom_class] = class_indices[dom_class][n_dom:]\n",
    "\n",
    "    for c in range(n_classes):\n",
    "        rem = class_indices[c]\n",
    "        np.random.shuffle(rem)\n",
    "        others = [i for i in range(num_clients) if i % n_classes != c]\n",
    "        for i, idx in enumerate(rem):\n",
    "            client_indices[others[i % len(others)]].append(idx)\n",
    "    for i in range(num_clients):\n",
    "        np.random.shuffle(client_indices[i])\n",
    "    return client_indices\n",
    "\n",
    "def load_medmnist_data(args):\n",
    "    train_t, test_t = get_transforms()\n",
    "    root = './data/medmnist'\n",
    "    os.makedirs(root, exist_ok=True)\n",
    "    Dataset = DATASET_MAP[args.dataset]\n",
    "\n",
    "    train = Dataset(root=root, split='train', download=True, transform=train_t)\n",
    "    val = Dataset(root=root, split='val', download=True, transform=train_t)\n",
    "    test = Dataset(root=root, split='test', download=True, transform=test_t)\n",
    "    combined = ConcatDataset([train, val])\n",
    "\n",
    "    cache = f'./data/medmnist/client_idx_{args.dataset}_K{args.K}_dr{args.dominant_ratio}_fedbn.pkl'\n",
    "    if os.path.exists(cache):\n",
    "        with open(cache, 'rb') as f:\n",
    "            client_idx = pickle.load(f)\n",
    "    else:\n",
    "        client_idx = balanced_noniid_split(combined, args.K, args.dominant_ratio)\n",
    "        with open(cache, 'wb') as f:\n",
    "            pickle.dump(client_idx, f)\n",
    "\n",
    "    client_loaders = [\n",
    "        DataLoader(Subset(combined, idx), batch_size=args.B, shuffle=True, num_workers=0)\n",
    "        for idx in client_idx\n",
    "    ]\n",
    "    test_loader = DataLoader(test, batch_size=args.B, shuffle=False, num_workers=0)\n",
    "    return client_loaders, test_loader\n",
    "\n",
    "'''\n",
    "\n",
    "with open(file_path, \"w\") as f:\n",
    "    f.write(new_code)\n",
    "\n",
    "print(\" get_data.py created for FedBN!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "file_path = \"/kaggle/working/FedBn-PyTorch/client.py\"\n",
    "\n",
    "new_code = \"\"\"# ========================================\n",
    "# client.py â€” Client-side helper for FedBN (with gradient clipping)\n",
    "# ========================================\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "\n",
    "class Client:\n",
    "    def __init__(self, model, train_loader, device, val_loader=None,\n",
    "                 lr=0.001, weight_decay=1e-4, use_fedbn=True):\n",
    "        \\\"\\\"\\\"\n",
    "        Args:\n",
    "            use_fedbn (bool): If True, BN layers remain local (not aggregated)\n",
    "        \\\"\\\"\\\"\n",
    "        self.model = model.to(device)\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.device = device\n",
    "        self.lr = lr\n",
    "        self.weight_decay = weight_decay\n",
    "        self.use_fedbn = use_fedbn\n",
    "\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=self.lr, weight_decay=self.weight_decay)\n",
    "\n",
    "    def compute_accuracy(self, loader):\n",
    "        \\\"\\\"\\\"Compute accuracy on given DataLoader\\\"\\\"\\\"\n",
    "        self.model.eval()\n",
    "        correct, total = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in loader:\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                labels = labels.squeeze()\n",
    "                if labels.dim() == 0:\n",
    "                    labels = labels.unsqueeze(0)\n",
    "                if labels.size(0) == 0:\n",
    "                    continue\n",
    "                outputs = self.model(images)\n",
    "                if isinstance(outputs, tuple) or hasattr(outputs, 'logits'):\n",
    "                    outputs = outputs.logits\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        return 100 * correct / total if total > 0 else 0\n",
    "\n",
    "    def train(self, epochs=1):\n",
    "        \\\"\\\"\\\"Local training (BN layers remain local; only non-BN parameters aggregated)\\\"\\\"\\\"\n",
    "        print()\n",
    "        print(\" Training client model with FedBN objective...\")\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            self.model.train()\n",
    "            total_loss = 0.0\n",
    "            batch_count = 0\n",
    "\n",
    "            pbar = tqdm(self.train_loader,\n",
    "                        desc=f\"  Epoch {epoch+1}/{epochs}\",\n",
    "                        ncols=100,\n",
    "                        leave=False)\n",
    "\n",
    "            for images, labels in pbar:\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                labels = labels.squeeze()\n",
    "                if labels.dim() == 0:\n",
    "                    labels = labels.unsqueeze(0)\n",
    "                if labels.size(0) == 0:\n",
    "                    continue\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                outputs = self.model(images)\n",
    "                if isinstance(outputs, tuple) or hasattr(outputs, 'logits'):\n",
    "                    outputs = outputs.logits\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                \n",
    "                # Check for NaN and skip if found\n",
    "                if torch.isnan(loss):\n",
    "                    print(\"  NaN detected, skipping batch\")\n",
    "                    continue\n",
    "                \n",
    "                loss.backward()\n",
    "                \n",
    "                # Gradient clipping for stability\n",
    "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
    "                \n",
    "                self.optimizer.step()\n",
    "\n",
    "                total_loss += loss.item()\n",
    "                batch_count += 1\n",
    "                pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "            \n",
    "            avg_loss = total_loss / batch_count if batch_count > 0 else 0\n",
    "            train_acc = self.compute_accuracy(self.train_loader)\n",
    "            log_msg = f\"  Epoch {epoch+1:2d}/{epochs} | Loss: {avg_loss:.4f} | Train Acc: {train_acc:.2f}%\"\n",
    "\n",
    "            if self.val_loader is not None:\n",
    "                val_acc = self.compute_accuracy(self.val_loader)\n",
    "                val_loss, val_batches = 0.0, 0\n",
    "                self.model.eval()\n",
    "                with torch.no_grad():\n",
    "                    for images, labels in self.val_loader:\n",
    "                        images, labels = images.to(self.device), labels.to(self.device)\n",
    "                        labels = labels.squeeze()\n",
    "                        if labels.dim() == 0:\n",
    "                            labels = labels.unsqueeze(0)\n",
    "                        if labels.size(0) == 0:\n",
    "                            continue\n",
    "                        outputs = self.model(images)\n",
    "                        if isinstance(outputs, tuple) or hasattr(outputs, 'logits'):\n",
    "                            outputs = outputs.logits\n",
    "                        loss = self.criterion(outputs, labels)\n",
    "                        val_loss += loss.item()\n",
    "                        val_batches += 1\n",
    "                val_loss = val_loss / val_batches if val_batches > 0 else 0\n",
    "                log_msg += f\" | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%\"\n",
    "\n",
    "            print(log_msg)\n",
    "        \n",
    "        print(\" Client local training complete (FedBN)\")\n",
    "        print()\n",
    "        return self.model.state_dict()\n",
    "\"\"\"\n",
    "\n",
    "with open(file_path, \"w\") as f:\n",
    "    f.write(new_code)\n",
    "\n",
    "print(\" client.py updated!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "file_path = \"/kaggle/working/FedBn-PyTorch/model.py\"\n",
    "\n",
    "new_code = '''\n",
    "# ========================================\n",
    "# model.py â€“ CLIP-based FedBN (Gradient-Compatible)\n",
    "# ========================================\n",
    "import torch\n",
    "from torch import nn\n",
    "import clip\n",
    "\n",
    "class CLIPFedBNClassifier(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super().__init__()\n",
    "        self.args = args\n",
    "        self.clip_model, _ = clip.load(args.clip_model, device=args.device)\n",
    "        \n",
    "        # Freeze CLIP by default (but allow gradient computation for attacks)\n",
    "        for p in self.clip_model.parameters():\n",
    "            p.requires_grad = False\n",
    "        \n",
    "        feature_dim = self.clip_model.visual.output_dim\n",
    "        \n",
    "        # Classification head\n",
    "        self.fc1 = nn.Linear(feature_dim, 256)\n",
    "        self.bn1 = nn.BatchNorm1d(256)\n",
    "        self.fc2 = nn.Linear(256, args.num_classes)\n",
    "        self.bn2 = nn.BatchNorm1d(args.num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.drop = nn.Dropout(args.dropout)\n",
    "    \n",
    "    def forward(self, x, enable_grad=False):\n",
    "        \"\"\"\n",
    "        Forward pass with optional gradient computation\n",
    "        \n",
    "        Args:\n",
    "            x: Input images\n",
    "            enable_grad: If True, compute gradients through CLIP (for attacks)\n",
    "        \"\"\"\n",
    "        if enable_grad:\n",
    "            # For adversarial attacks - enable gradients through CLIP\n",
    "            # This allows attacks to perturb inputs effectively\n",
    "            img_feat = self.clip_model.encode_image(x).float()\n",
    "        else:\n",
    "            # Normal training/inference - no gradients through CLIP\n",
    "            with torch.no_grad():\n",
    "                img_feat = self.clip_model.encode_image(x).float()\n",
    "        \n",
    "        # Classification head (always has gradients during training)\n",
    "        x = self.fc1(img_feat)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.bn2(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def get_bn_params(self):\n",
    "        \"\"\"\n",
    "        Return list of BatchNorm parameter names\n",
    "        These should be excluded from FedBN aggregation\n",
    "        \"\"\"\n",
    "        bn_params = []\n",
    "        for name, module in self.named_modules():\n",
    "            if isinstance(module, (nn.BatchNorm1d, nn.BatchNorm2d)):\n",
    "                # Get all BN-related parameters\n",
    "                for param_name in ['weight', 'bias', 'running_mean', 'running_var', \n",
    "                                   'num_batches_tracked']:\n",
    "                    full_name = f\"{name}.{param_name}\"\n",
    "                    bn_params.append(full_name)\n",
    "        return bn_params\n",
    "    \n",
    "    def extract_features(self, x):\n",
    "        \"\"\"\n",
    "        Extract CLIP features (useful for analysis)\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            return self.clip_model.encode_image(x).float()\n",
    "'''\n",
    "\n",
    "with open(file_path, \"w\") as f:\n",
    "    f.write(new_code)\n",
    "\n",
    "print(\" model.py fixed!\")\n",
    "print(f\" File path: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "file_path = \"/kaggle/working/FedBn-PyTorch/attacks.py\"\n",
    "\n",
    "new_code = \"\"\"\n",
    "# ========================================\n",
    "# attacks.py â€“ Fixed Adversarial Attacks for FedBN\n",
    "# ========================================\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class AdversarialAttacks:\n",
    "    def __init__(self, model, device):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    def fgsm_attack(self, images, labels, epsilon=0.03):\n",
    "       \n",
    "        self.model.eval()\n",
    "        \n",
    "        # Clone and enable gradients\n",
    "        images = images.clone().detach().to(self.device)\n",
    "        labels = labels.to(self.device)\n",
    "        images.requires_grad = True\n",
    "        \n",
    "        # Forward pass with gradient tracking\n",
    "        outputs = self.model(images, enable_grad=True)\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        \n",
    "        # Compute gradients\n",
    "        self.model.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # Check if gradients exist\n",
    "        if images.grad is None:\n",
    "            print(\"    No gradients computed - attack failed\")\n",
    "            return images.detach()\n",
    "        \n",
    "        # Create perturbation\n",
    "        # Scale epsilon for normalized space [-1, 1]\n",
    "        # Since your images are in [-1, 1], epsilon acts differently than [0, 1]\n",
    "        perturbation = epsilon * images.grad.sign()\n",
    "        \n",
    "        # Create adversarial images\n",
    "        adv_images = images + perturbation\n",
    "        adv_images = torch.clamp(adv_images, -1, 1)  # Match your normalization\n",
    "        \n",
    "        return adv_images.detach()\n",
    "    \n",
    "    def pgd_attack(self, images, labels, epsilon=0.03, alpha=0.007, iters=10):\n",
    "        \n",
    "        self.model.eval()\n",
    "        \n",
    "        images = images.clone().detach().to(self.device)\n",
    "        labels = labels.to(self.device)\n",
    "        \n",
    "        # Initialize with random perturbation (recommended for PGD)\n",
    "        adv_images = images.clone()\n",
    "        adv_images = adv_images + torch.empty_like(adv_images).uniform_(-epsilon, epsilon)\n",
    "        adv_images = torch.clamp(adv_images, -1, 1)\n",
    "        \n",
    "        for i in range(iters):\n",
    "            adv_images.requires_grad = True\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = self.model(adv_images, enable_grad=True)\n",
    "            loss = self.criterion(outputs, labels)\n",
    "            \n",
    "            # Compute gradients\n",
    "            self.model.zero_grad()\n",
    "            if adv_images.grad is not None:\n",
    "                adv_images.grad.zero_()\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            # Check gradients\n",
    "            if adv_images.grad is None:\n",
    "                print(f\"   âš ï¸ No gradients at iteration {i+1}\")\n",
    "                break\n",
    "            \n",
    "            # Update with gradient ascent\n",
    "            with torch.no_grad():\n",
    "                # Take step in direction of gradient\n",
    "                adv_images = adv_images.detach() + alpha * adv_images.grad.sign()\n",
    "                \n",
    "                # Project back to epsilon ball around original image\n",
    "                perturbation = torch.clamp(adv_images - images, -epsilon, epsilon)\n",
    "                adv_images = images + perturbation\n",
    "                \n",
    "                # Ensure valid range\n",
    "                adv_images = torch.clamp(adv_images, -1, 1)\n",
    "        \n",
    "        return adv_images.detach()\n",
    "    \n",
    "    def cw_attack(self, images, labels, c=1.0, kappa=0, max_iter=100, learning_rate=0.01):\n",
    "       \n",
    "        self.model.eval()\n",
    "        \n",
    "        images = images.clone().detach().to(self.device)\n",
    "        labels = labels.to(self.device)\n",
    "        batch_size = images.shape[0]\n",
    "        \n",
    "        # Use tanh space for better optimization\n",
    "        # Transform: x = 0.5 * (tanh(w) + 1) * 2 - 1  for [-1,1] range\n",
    "        w = torch.zeros_like(images, requires_grad=True, device=self.device)\n",
    "        optimizer = torch.optim.Adam([w], lr=learning_rate)\n",
    "        \n",
    "        best_adv = images.clone()\n",
    "        best_loss = float('inf') * torch.ones(batch_size, device=self.device)\n",
    "        \n",
    "        for step in range(max_iter):\n",
    "            # Transform w to valid image range\n",
    "            adv_images = torch.tanh(w) * 1.0  # Maps to [-1, 1]\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = self.model(adv_images, enable_grad=True)\n",
    "            \n",
    "            # CW loss formulation\n",
    "            # f(x) = max(Z_target - max(Z_other), -kappa)\n",
    "            real = outputs.gather(1, labels.unsqueeze(1)).squeeze(1)\n",
    "            \n",
    "            # Get second highest logit\n",
    "            other = outputs.clone()\n",
    "            other.scatter_(1, labels.unsqueeze(1), -float('inf'))\n",
    "            other_max = other.max(1)[0]\n",
    "            \n",
    "            # Loss: want other_max > real (misclassification)\n",
    "            f_loss = torch.clamp(real - other_max + kappa, min=0)\n",
    "            \n",
    "            # L2 distance loss\n",
    "            l2_dist = torch.sum((adv_images - images) ** 2, dim=[1, 2, 3])\n",
    "            \n",
    "            # Combined loss\n",
    "            loss = (c * f_loss + l2_dist).sum()\n",
    "            \n",
    "            # Optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Track best adversarial examples\n",
    "            with torch.no_grad():\n",
    "                pred = outputs.argmax(1)\n",
    "                successful = (pred != labels)\n",
    "                \n",
    "                for i in range(batch_size):\n",
    "                    if successful[i] and l2_dist[i] < best_loss[i]:\n",
    "                        best_loss[i] = l2_dist[i]\n",
    "                        best_adv[i] = adv_images[i]\n",
    "        \n",
    "        return best_adv.detach()\n",
    "\n",
    "\n",
    "def test_attacks_quickly(model, test_loader, device, args):\n",
    "   \n",
    "    attacker = AdversarialAttacks(model, device)\n",
    "    \n",
    "    # Get one batch\n",
    "    images, labels = next(iter(test_loader))\n",
    "    images, labels = images.to(device), labels.squeeze().to(device)\n",
    "    \n",
    "    print(\"\\\\n\" + \"=\"*60)\n",
    "    print(\" QUICK ATTACK TEST\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Test clean accuracy\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        clean_outputs = model(images)\n",
    "        clean_pred = clean_outputs.argmax(1)\n",
    "        clean_acc = (clean_pred == labels).float().mean().item() * 100\n",
    "    \n",
    "    print(f\"Clean Accuracy: {clean_acc:.2f}%\")\n",
    "    \n",
    "    # Test FGSM\n",
    "    print(\"\\\\n Testing FGSM...\")\n",
    "    fgsm_images = attacker.fgsm_attack(images, labels, epsilon=args.attack_epsilon)\n",
    "    with torch.no_grad():\n",
    "        fgsm_outputs = model(fgsm_images)\n",
    "        fgsm_pred = fgsm_outputs.argmax(1)\n",
    "        fgsm_acc = (fgsm_pred == labels).float().mean().item() * 100\n",
    "    print(f\"FGSM Accuracy: {fgsm_acc:.2f}% (Drop: {clean_acc - fgsm_acc:.2f}%)\")\n",
    "    \n",
    "    # Test PGD\n",
    "    print(\"\\\\n Testing PGD...\")\n",
    "    pgd_images = attacker.pgd_attack(images, labels, \n",
    "                                     epsilon=args.attack_epsilon,\n",
    "                                     alpha=args.pgd_alpha,\n",
    "                                     iters=args.pgd_iters)\n",
    "    with torch.no_grad():\n",
    "        pgd_outputs = model(pgd_images)\n",
    "        pgd_pred = pgd_outputs.argmax(1)\n",
    "        pgd_acc = (pgd_pred == labels).float().mean().item() * 100\n",
    "    print(f\"PGD Accuracy: {pgd_acc:.2f}% (Drop: {clean_acc - pgd_acc:.2f}%)\")\n",
    "    \n",
    "    # Perturbation analysis\n",
    "    fgsm_pert = (fgsm_images - images).abs().mean().item()\n",
    "    pgd_pert = (pgd_images - images).abs().mean().item()\n",
    "    \n",
    "    print(\"\\\\n Perturbation Statistics:\")\n",
    "    print(f\"FGSM - Mean: {fgsm_pert:.6f}, Max: {(fgsm_images - images).abs().max().item():.6f}\")\n",
    "    print(f\"PGD  - Mean: {pgd_pert:.6f}, Max: {(pgd_images - images).abs().max().item():.6f}\")\n",
    "    print(\"=\"*60)\n",
    "\"\"\"\n",
    "\n",
    "with open(file_path, \"w\") as f:\n",
    "    f.write(new_code)\n",
    "\n",
    "print(\" attacks.py updated (clean implementation)!\")\n",
    "print(f\" File path: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "file_path = \"/kaggle/working/FedBn-PyTorch/server.py\"\n",
    "\n",
    "new_code = '''\n",
    "# ========================================\n",
    "# server.py â€“ FedBN Server (FIXED Attack Testing)\n",
    "# ========================================\n",
    "import torch\n",
    "import copy\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "from client import Client\n",
    "from model import CLIPFedBNClassifier\n",
    "from get_data import load_medmnist_data\n",
    "from attacks import AdversarialAttacks\n",
    "\n",
    "class FedBNServer:\n",
    "    def __init__(self, args):\n",
    "        self.args = args\n",
    "        self.device = args.device\n",
    "        \n",
    "        # Initialize global model\n",
    "        self.global_model = CLIPFedBNClassifier(args).to(self.device)\n",
    "        \n",
    "        # Get BN params to exclude from aggregation\n",
    "        self.bn_params = set(self.global_model.get_bn_params())\n",
    "        print(f\" Excluded BN parameters: {len(self.bn_params)} params\")\n",
    "        \n",
    "        # Load data\n",
    "        print(\"\\\\n Loading dataset...\")\n",
    "        self.client_loaders, self.test_loader = load_medmnist_data(args)\n",
    "        print(f\" Loaded {len(self.client_loaders)} clients\")\n",
    "        \n",
    "        # Training state\n",
    "        self.current_round = 0\n",
    "        self.best_global_acc = 0\n",
    "        self.history = {\n",
    "            'rounds': [],\n",
    "            'avg_accuracy': [],\n",
    "            'best_accuracy': []\n",
    "        }\n",
    "        \n",
    "        # Create checkpoint directory\n",
    "        os.makedirs(args.checkpoint_dir, exist_ok=True)\n",
    "        \n",
    "        # Try to resume from checkpoint\n",
    "        self.resume_from_checkpoint()\n",
    "    \n",
    "    def resume_from_checkpoint(self):\n",
    "        \"\"\"Load checkpoint if exists\"\"\"\n",
    "        checkpoint_path = os.path.join(self.args.checkpoint_dir, 'checkpoint_latest.pth')\n",
    "        \n",
    "        if os.path.exists(checkpoint_path):\n",
    "            print(f\"\\\\n Found checkpoint at {checkpoint_path}. Resuming training...\")\n",
    "            try:\n",
    "                print(f\"\\\\n Loading checkpoint: {checkpoint_path}\")\n",
    "                checkpoint = torch.load(checkpoint_path, map_location=self.device, weights_only=False)\n",
    "                \n",
    "                self.global_model.load_state_dict(checkpoint['server_state_dict'])\n",
    "                self.current_round = checkpoint['round']\n",
    "                self.best_global_acc = checkpoint.get('best_global_acc', 0)\n",
    "                self.history = checkpoint.get('history', self.history)\n",
    "                \n",
    "                print(f\" Resumed from Round {self.current_round} | Best Acc: {self.best_global_acc:.2f}%\")\n",
    "            except Exception as e:\n",
    "                print(f\" Error loading checkpoint: {e}\")\n",
    "                print(\"Starting fresh training...\")\n",
    "                self.current_round = 0\n",
    "    \n",
    "    def fedbn_aggregate(self, client_states):\n",
    "        \"\"\"\n",
    "        FedBN aggregation: Average only non-BN parameters\n",
    "        BN statistics remain local to each client\n",
    "        \"\"\"\n",
    "        global_dict = self.global_model.state_dict()\n",
    "        \n",
    "        # Average non-BN parameters\n",
    "        for key in global_dict.keys():\n",
    "            if key not in self.bn_params:\n",
    "                # Average this parameter across clients\n",
    "                global_dict[key] = torch.stack([\n",
    "                    client_states[i][key].float() for i in range(len(client_states))\n",
    "                ]).mean(0)\n",
    "        \n",
    "        self.global_model.load_state_dict(global_dict)\n",
    "    \n",
    "    def test_global_model(self):\n",
    "        \"\"\"\n",
    "        Test global model with optional adversarial attacks\n",
    "         FIXED: Each attack works on CLEAN images independently\n",
    "        \"\"\"\n",
    "        self.global_model.eval()\n",
    "        \n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        total_loss = 0\n",
    "        total_samples = 0\n",
    "        \n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "        \n",
    "        # Initialize attacker if needed\n",
    "        attacker = None\n",
    "        if self.args.attack_type != 'none':\n",
    "            attacker = AdversarialAttacks(self.global_model, self.device)\n",
    "            print(f\"\\\\n  Testing with {self.args.attack_type.upper()} attack (Îµ={self.args.attack_epsilon})\")\n",
    "        \n",
    "        # Use appropriate context based on attack type\n",
    "        context_manager = torch.no_grad() if self.args.attack_type == 'none' else torch.enable_grad()\n",
    "        \n",
    "        with context_manager:\n",
    "            for images, labels in tqdm(self.test_loader, desc=\"  Testing\", leave=False, ncols=100):\n",
    "                #  Store ORIGINAL clean images\n",
    "                original_images = images.clone()\n",
    "                \n",
    "                images, labels = images.to(self.device), labels.squeeze().to(self.device)\n",
    "                \n",
    "                #  Apply attack on ORIGINAL clean images (not modified images!)\n",
    "                if self.args.attack_type == 'fgsm':\n",
    "                    images = attacker.fgsm_attack(original_images.to(self.device), labels, \n",
    "                                                   self.args.attack_epsilon)\n",
    "                elif self.args.attack_type == 'pgd':\n",
    "                    images = attacker.pgd_attack(\n",
    "                        original_images.to(self.device), labels,  \n",
    "                        epsilon=self.args.attack_epsilon,\n",
    "                        alpha=self.args.pgd_alpha,\n",
    "                        iters=self.args.pgd_iters\n",
    "                    )\n",
    "                elif self.args.attack_type == 'cw':\n",
    "                    images = attacker.cw_attack(\n",
    "                        original_images.to(self.device), labels,  \n",
    "                        c=self.args.cw_c,\n",
    "                        max_iter=self.args.cw_max_iter\n",
    "                    )\n",
    "                \n",
    "                # Get predictions\n",
    "                with torch.no_grad():\n",
    "                    outputs = self.global_model(images)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    _, predicted = torch.max(outputs, 1)\n",
    "                \n",
    "                all_preds.extend(predicted.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "                total_loss += loss.item() * labels.size(0)\n",
    "                total_samples += labels.size(0)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracy = 100.0 * np.mean(np.array(all_preds) == np.array(all_labels))\n",
    "        avg_loss = total_loss / total_samples\n",
    "        \n",
    "        precision = precision_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "        recall = recall_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "        f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "        \n",
    "        # RMSE\n",
    "        rmse = np.sqrt(np.mean((np.array(all_preds) - np.array(all_labels)) ** 2))\n",
    "        \n",
    "        return {\n",
    "            'accuracy': accuracy,\n",
    "            'loss': avg_loss,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1': f1,\n",
    "            'rmse': rmse\n",
    "        }\n",
    "    \n",
    "    def save_checkpoint(self, round_num, is_best=False):\n",
    "        \"\"\"Save checkpoint\"\"\"\n",
    "        checkpoint = {\n",
    "            'round': round_num,\n",
    "            'server_state_dict': self.global_model.state_dict(),\n",
    "            'best_global_acc': self.best_global_acc,\n",
    "            'history': self.history,\n",
    "            'args': vars(self.args)\n",
    "        }\n",
    "        \n",
    "        # Save latest checkpoint\n",
    "        latest_path = os.path.join(self.args.checkpoint_dir, 'checkpoint_latest.pth')\n",
    "        torch.save(checkpoint, latest_path)\n",
    "        \n",
    "        # Save best checkpoint if applicable\n",
    "        if is_best:\n",
    "            best_path = os.path.join(self.args.checkpoint_dir, 'checkpoint_best.pth')\n",
    "            torch.save(checkpoint, best_path)\n",
    "            print(f\"   Saved best checkpoint (Acc: {self.best_global_acc:.2f}%)\")\n",
    "    \n",
    "    def run(self):\n",
    "        \"\"\"Run federated learning\"\"\"\n",
    "        print(\"\\\\n\" + \"=\"*60)\n",
    "        print(\" STARTING FEDBN TRAINING\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        for round_num in range(self.current_round + 1, self.args.r + 1):\n",
    "            print(f\"\\\\n{'='*60}\")\n",
    "            print(f\" COMMUNICATION ROUND {round_num}/{self.args.r}\")\n",
    "            print('='*60)\n",
    "            \n",
    "            # Select clients\n",
    "            num_selected = max(1, int(self.args.C * self.args.K))\n",
    "            selected_clients = np.random.choice(self.args.K, num_selected, replace=False)\n",
    "            print(f\" Selected {num_selected} clients: {selected_clients.tolist()}\")\n",
    "            \n",
    "            # Collect client updates\n",
    "            client_states = []\n",
    "            \n",
    "            for client_id in selected_clients:\n",
    "                print(f\"\\\\n Training Client {client_id+1}/{self.args.K}\")\n",
    "                \n",
    "                # Create client with global model\n",
    "                client_model = copy.deepcopy(self.global_model)\n",
    "                client = Client(\n",
    "                    model=client_model,\n",
    "                    train_loader=self.client_loaders[client_id],\n",
    "                    device=self.device,\n",
    "                    lr=self.args.lr,\n",
    "                    weight_decay=self.args.weight_decay,\n",
    "                    use_fedbn=True\n",
    "                )\n",
    "                \n",
    "                # Train locally\n",
    "                updated_state = client.train(epochs=self.args.E)\n",
    "                client_states.append(updated_state)\n",
    "            \n",
    "            # FedBN Aggregation (exclude BN params)\n",
    "            print(f\"\\\\n Aggregating {len(client_states)} client models (FedBN)...\")\n",
    "            self.fedbn_aggregate(client_states)\n",
    "            \n",
    "            # Test global model\n",
    "            print(\"\\\\n Testing global model...\")\n",
    "            metrics = self.test_global_model()\n",
    "            \n",
    "            # Update history\n",
    "            self.history['rounds'].append(r+1)\n",
    "            self.history['avg_accuracy'].append(avg_acc)\n",
    "            self.history['precision'] = self.history.get('precision', []) + [metrics['precision']]\n",
    "            self.history['recall'] = self.history.get('recall', []) + [metrics['recall']]\n",
    "            self.history['f1'] = self.history.get('f1', []) + [metrics['f1']]\n",
    "            self.history['rmse'] = self.history.get('rmse', []) + [metrics['rmse']]\n",
    "            \n",
    "            # Check if best\n",
    "            is_best = metrics['accuracy'] > self.best_global_acc\n",
    "            if is_best:\n",
    "                self.best_global_acc = metrics['accuracy']\n",
    "            \n",
    "            # Print results\n",
    "            print(f\"\\\\n Round {round_num} Results:\")\n",
    "            print(f\"   Accuracy:  {metrics['accuracy']:.2f}%\")\n",
    "            print(f\"   Loss:      {metrics['loss']:.4f}\")\n",
    "            print(f\"   Precision: {metrics['precision']:.4f}\")\n",
    "            print(f\"   Recall:    {metrics['recall']:.4f}\")\n",
    "            print(f\"   F1-Score:  {metrics['f1']:.4f}\")\n",
    "            print(f\"   Best Ever: {self.best_global_acc:.2f}%\")\n",
    "            \n",
    "            # Save checkpoint\n",
    "            self.current_round = round_num\n",
    "            self.save_checkpoint(round_num, is_best)\n",
    "        \n",
    "        print(\"\\\\n\" + \"=\"*60)\n",
    "        print(\"âœ… FEDBN TRAINING COMPLETED\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        return self.global_model\n",
    "'''\n",
    "\n",
    "with open(file_path, \"w\") as f:\n",
    "    f.write(new_code)\n",
    "\n",
    "print(\" server.py FIXED - Each attack now works on clean images!\")\n",
    "print(f\" File path: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "file_path = \"/kaggle/working/FedBn-PyTorch/main.py\"\n",
    "\n",
    "new_code = '''# ========================================\n",
    "# main.py â€” Run FedBN with CLIP model (Auto Resume)\n",
    "# ========================================\n",
    "from args import args_parser\n",
    "from server import FedBNServer\n",
    "import torch\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_training_history(history, save_path):\n",
    "    \"\"\"Plot training accuracy curves\"\"\"\n",
    "    if not history['rounds']:\n",
    "        print(\"  No training history to plot\")\n",
    "        return\n",
    "    \n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Plot 1: Average Accuracy\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history['rounds'], history['avg_accuracy'], 'b-', label='Avg Accuracy', linewidth=2)\n",
    "    plt.plot(history['rounds'], history['best_accuracy'], 'r--', label='Best Accuracy', linewidth=2)\n",
    "    plt.xlabel('Communication Round')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.title('Federated Learning Accuracy Progress')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Accuracy Improvement\n",
    "    plt.subplot(1, 2, 2)\n",
    "    if len(history['avg_accuracy']) > 1:\n",
    "        improvements = [history['avg_accuracy'][i] - history['avg_accuracy'][i-1] \n",
    "                        for i in range(1, len(history['avg_accuracy']))]\n",
    "        plt.bar(history['rounds'][1:], improvements, alpha=0.7)\n",
    "        plt.axhline(y=0, color='r', linestyle='-', linewidth=0.5)\n",
    "        plt.xlabel('Communication Round')\n",
    "        plt.ylabel('Accuracy Change (%)')\n",
    "        plt.title('Round-to-Round Accuracy Change')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f' Training plot saved at: {save_path}')\n",
    "\n",
    "\n",
    "def test_with_all_attacks(server, args):\n",
    " \n",
    "    attacks = ['none', 'fgsm', 'pgd', 'cw']\n",
    "    results = {}\n",
    "    \n",
    "    print('\\\\n' + '='*60)\n",
    "    print('  ADVERSARIAL ROBUSTNESS TESTING')\n",
    "    print('='*60)\n",
    "    \n",
    "    for attack in attacks:\n",
    "        original_attack = args.attack_type\n",
    "        args.attack_type = attack\n",
    "        \n",
    "        print(f\"\\\\n{'='*60}\")\n",
    "        print(f\" Testing with {attack.upper()} attack\")\n",
    "        print('='*60)\n",
    "        \n",
    "        metrics = server.test_global_model()\n",
    "        results[attack] = metrics\n",
    "        \n",
    "        print(f\"\\\\n Results:\")\n",
    "        print(f\"    Accuracy:  {metrics['accuracy']:.2f}%\")\n",
    "        print(f\"    Precision: {metrics['precision']:.4f}\")\n",
    "        print(f\"    Recall:    {metrics['recall']:.4f}\")\n",
    "        print(f\"    F1-Score:  {metrics['f1']:.4f}\")\n",
    "        print(f\"    RMSE:      {metrics['rmse']:.4f}\")\n",
    "    \n",
    "    args.attack_type = original_attack\n",
    "    \n",
    "    # Save results\n",
    "    results_path = os.path.join(args.checkpoint_dir, 'attack_results.json')\n",
    "    with open(results_path, 'w') as f:\n",
    "        json.dump(results, f, indent=4)\n",
    "    print(f\"\\\\n Attack results saved at: {results_path}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def main():\n",
    "    # Load arguments\n",
    "    args = args_parser()\n",
    "    \n",
    "    # Print configuration\n",
    "    print('\\\\n' + '='*60)\n",
    "    print(' FEDBN TRAINING CONFIGURATION (CLIP Model)')\n",
    "    print('='*60)\n",
    "    print(f'Device: {args.device}')\n",
    "    print(f'Clients: {args.K} | Rounds: {args.r} | Local Epochs: {args.E}')\n",
    "    print(f'Batch Size: {args.B} | Learning Rate: {args.lr}')\n",
    "    print(f'Non-IID: {args.dominant_ratio*100:.0f}% dominant class per client')\n",
    "    print(f'Checkpoint Directory: {args.checkpoint_dir}')\n",
    "    print('='*60)\n",
    "    \n",
    "    # Check if checkpoint exists (just for info - server will auto-resume)\n",
    "    latest_checkpoint = os.path.join(args.checkpoint_dir, 'checkpoint_latest.pth')\n",
    "    if os.path.exists(latest_checkpoint):\n",
    "        print('\\\\n' + '='*60)\n",
    "        print(' CHECKPOINT FOUND - Will auto-resume')\n",
    "        print('='*60)\n",
    "        try:\n",
    "            checkpoint = torch.load(latest_checkpoint, map_location=args.device, weights_only=False)\n",
    "            completed_rounds = checkpoint.get('round', 0)\n",
    "            best_acc = checkpoint.get('best_global_acc', 0)\n",
    "            print(f' Checkpoint Details:')\n",
    "            print(f'   - Completed Rounds: {completed_rounds}/{args.r}')\n",
    "            print(f'   - Best Accuracy: {best_acc:.2f}%')\n",
    "        except Exception as e:\n",
    "            print(f'  Error reading checkpoint: {e}')\n",
    "    else:\n",
    "        print('\\\\n' + '='*60)\n",
    "        print(' No checkpoint found. Starting fresh training...')\n",
    "        print('='*60)\n",
    "    \n",
    "    # Initialize FedBN server (auto-resumes if checkpoint exists)\n",
    "    server = FedBNServer(args)\n",
    "    \n",
    "      # Check if training is complete\n",
    "    if server.current_round == args.r:\n",
    "        print('\\\\n Training already complete!')\n",
    "        print(f' Running adversarial robustness testing...')\n",
    "        attack_results = test_with_all_attacks(server, args)\n",
    "        \n",
    "        # Print final attack comparison\n",
    "        print('\\\\n' + '='*60)\n",
    "        print(' ATTACK RESULTS COMPARISON')\n",
    "        print('='*60)\n",
    "        print(f\"{'Attack Type':<15} {'Accuracy':<10} {'Precision':<10} {'Recall':<10} {'F1-Score'}\")\n",
    "        print('-'*60)\n",
    "        for attack, metrics in attack_results.items():\n",
    "            print(f\"{attack.upper():<15} {metrics['accuracy']:>6.2f}%    {metrics['precision']:>7.4f}    {metrics['recall']:>7.4f}    {metrics['f1']:>7.4f}\")\n",
    "        print('='*60)\n",
    "    else:\n",
    "        # Run federated training\n",
    "        final_model = server.run()\n",
    "        \n",
    "        # Save final global model\n",
    "        final_model_path = os.path.join(args.checkpoint_dir, 'final_global_model.pth')\n",
    "        torch.save(final_model.state_dict(), final_model_path)\n",
    "        print(f'\\\\n Final global model saved at: {final_model_path}')\n",
    "        \n",
    "        # Save training history\n",
    "        history_path = os.path.join(args.checkpoint_dir, 'training_history.json')\n",
    "        with open(history_path, 'w') as f:\n",
    "            json.dump(server.history, f, indent=4)\n",
    "        print(f' Training history saved at: {history_path}')\n",
    "        \n",
    "        # Plot training curves\n",
    "        plot_path = os.path.join(args.checkpoint_dir, 'training_plot.png')\n",
    "        plot_training_history(server.history, plot_path)\n",
    "        \n",
    "        # Print summary\n",
    "        print('\\\\n' + '='*60)\n",
    "        print(' TRAINING SUMMARY')\n",
    "        print('='*60)\n",
    "        print(f' Best Global Accuracy: {server.best_global_acc:.2f}%')\n",
    "        print(f' Final Round Accuracy: {server.history[\\\"avg_accuracy\\\"][-1]:.2f}%')\n",
    "        print(f' Total Improvement: {server.history[\\\"avg_accuracy\\\"][-1] - server.history[\\\"avg_accuracy\\\"][0]:.2f}%')\n",
    "        print(f' All checkpoints saved in: {args.checkpoint_dir}')\n",
    "        print('='*60)\n",
    "        \n",
    "        # Test with attacks after training\n",
    "        print('\\\\n Testing adversarial robustness...')\n",
    "        attack_results = test_with_all_attacks(server, args)\n",
    "        \n",
    "        # Print final attack comparison\n",
    "        print('\\\\n' + '='*60)\n",
    "        print(' ATTACK RESULTS COMPARISON')\n",
    "        print('='*60)\n",
    "        print(f\"{'Attack Type':<15} {'Accuracy':<10} {'Precision':<10} {'Recall':<10} {'F1-Score'}\")\n",
    "        print('-'*60)\n",
    "        for attack, metrics in attack_results.items():\n",
    "            print(f\"{attack.upper():<15} {metrics['accuracy']:>6.2f}%    {metrics['precision']:>7.4f}    {metrics['recall']:>7.4f}    {metrics['f1']:>7.4f}\")\n",
    "        print('='*60)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "'''\n",
    "\n",
    "with open(file_path, \"w\") as f:\n",
    "    f.write(new_code)\n",
    "\n",
    "print(\" FedBN main.py saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install medmnist --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/openai/CLIP.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "file_path = \"/kaggle/working/FedBn-PyTorch/quick_attack_test.py\"\n",
    "\n",
    "new_code = \"\"\"\n",
    "# ========================================\n",
    "# quick_attack_test.py â€” Quick Attack Test for FedBN\n",
    "# ========================================\n",
    "from args import args_parser\n",
    "from model import CLIPFedBNClassifier  \n",
    "from attacks import AdversarialAttacks\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from get_data import get_transforms\n",
    "from medmnist import PathMNIST, TissueMNIST, OrganAMNIST, OCTMNIST\n",
    "\n",
    "DATASET_MAP = {\n",
    "    'pathmnist': PathMNIST,\n",
    "    'tissuemnist': TissueMNIST,\n",
    "    'organamnist': OrganAMNIST,\n",
    "    'octmnist': OCTMNIST\n",
    "}\n",
    "\n",
    "def quick_attack_test():\n",
    "    # Load arguments\n",
    "    args = args_parser()\n",
    "    \n",
    "    print('\\\\n' + '='*60)\n",
    "    print('âš¡ QUICK ATTACK TEST (10 images) - FedBN')\n",
    "    print('='*60)\n",
    "    print(f'Dataset: {args.dataset.upper()}')\n",
    "    print(f'Device: {args.device}')\n",
    "    print('='*60)\n",
    "    \n",
    "    # Load model - FedBN model doesn't need 'name' parameter\n",
    "    print('\\\\n Loading FedBN model...')\n",
    "    model = CLIPFedBNClassifier(args).to(args.device)  #  No 'name' parameter\n",
    "    \n",
    "    # Try to load checkpoint\n",
    "    checkpoint_path = os.path.join(args.checkpoint_dir, \"checkpoint_latest.pth\")\n",
    "    try:\n",
    "        if os.path.exists(checkpoint_path):\n",
    "            checkpoint = torch.load(checkpoint_path, map_location=args.device, weights_only=False)\n",
    "            model.load_state_dict(checkpoint['server_state_dict'])\n",
    "            print(f\" Loaded checkpoint from Round {checkpoint.get('round', 'unknown')}\")\n",
    "            print(f\"   Best Accuracy: {checkpoint.get('best_global_acc', 0):.2f}%\")\n",
    "        else:\n",
    "            print(f\"  No checkpoint found at: {checkpoint_path}\")\n",
    "            print(\"   Using random weights (model not trained yet)\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Error loading checkpoint: {e}\")\n",
    "        print(\"   Using random weights\")\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    # Load test data\n",
    "    print('\\\\n Loading test images...')\n",
    "    _, test_transform = get_transforms()\n",
    "    \n",
    "    # Create data directory if not exists\n",
    "    data_root = './data/medmnist'\n",
    "    os.makedirs(data_root, exist_ok=True)\n",
    "    \n",
    "    DatasetClass = DATASET_MAP[args.dataset]\n",
    "    test_dataset = DatasetClass(\n",
    "        root=data_root, \n",
    "        split='test', \n",
    "        download=True, \n",
    "        transform=test_transform\n",
    "    )\n",
    "    \n",
    "    # Select 10 random images\n",
    "    num_images = 10\n",
    "    np.random.seed(42)\n",
    "    indices = np.random.choice(len(test_dataset), num_images, replace=False)\n",
    "    subset = Subset(test_dataset, indices)\n",
    "    test_loader = DataLoader(subset, batch_size=num_images, shuffle=False)\n",
    "    \n",
    "    # Get batch\n",
    "    images, labels = next(iter(test_loader))\n",
    "    images = images.to(args.device)\n",
    "    labels = labels.squeeze().to(args.device)\n",
    "    \n",
    "    print(f\" Loaded {num_images} test images\")\n",
    "    print(f\" True labels: {labels.cpu().numpy()}\")\n",
    "    \n",
    "    # Initialize attacker\n",
    "    attacker = AdversarialAttacks(model, args.device)\n",
    "    \n",
    "    # Define attacks to test\n",
    "    attacks = {\n",
    "        'Clean (No Attack)': {\n",
    "            'fn': None,\n",
    "            'params': {}\n",
    "        },\n",
    "        'FGSM': {\n",
    "            'fn': attacker.fgsm_attack,\n",
    "            'params': {'epsilon': args.attack_epsilon}\n",
    "        },\n",
    "        'PGD': {\n",
    "            'fn': attacker.pgd_attack,\n",
    "            'params': {\n",
    "                'epsilon': args.attack_epsilon,\n",
    "                'alpha': args.pgd_alpha,\n",
    "                'iters': args.pgd_iters\n",
    "            }\n",
    "        },\n",
    "        'CW': {\n",
    "            'fn': attacker.cw_attack,\n",
    "            'params': {\n",
    "                'c': args.cw_c,\n",
    "                'max_iter': 50  # Reduced for quick test\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    print('\\\\n' + '='*60)\n",
    "    print('  TESTING ADVERSARIAL ATTACKS')\n",
    "    print('='*60)\n",
    "    \n",
    "    results = {}\n",
    "    adv_images_dict = {}\n",
    "    \n",
    "    for attack_name, attack_config in attacks.items():\n",
    "        print(f'\\\\n Testing: {attack_name}')\n",
    "        \n",
    "        if attack_config['fn'] is None:\n",
    "            # Clean images\n",
    "            test_images = images\n",
    "            print('   Using clean images...')\n",
    "        else:\n",
    "            # Apply attack\n",
    "            print(f'   Generating adversarial examples...')\n",
    "            print(f'   Parameters: {attack_config[\"params\"]}')\n",
    "            test_images = attack_config['fn'](images, labels, **attack_config['params'])\n",
    "        \n",
    "        adv_images_dict[attack_name] = test_images\n",
    "        \n",
    "        # Get predictions\n",
    "        with torch.no_grad():\n",
    "            outputs = model(test_images)\n",
    "            # FedBN model returns logits directly (no .logits attribute)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        correct = (predicted == labels).sum().item()\n",
    "        accuracy = 100.0 * correct / num_images\n",
    "        \n",
    "        results[attack_name] = {\n",
    "            'predictions': predicted.cpu().numpy(),\n",
    "            'accuracy': accuracy,\n",
    "            'correct': correct\n",
    "        }\n",
    "        \n",
    "        print(f'    Predictions: {predicted.cpu().numpy()}')\n",
    "        print(f'    Accuracy: {accuracy:.1f}% ({correct}/{num_images})')\n",
    "    \n",
    "    # Print comparison table\n",
    "    print('\\\\n' + '='*60)\n",
    "    print(' ATTACK RESULTS COMPARISON')\n",
    "    print('='*60)\n",
    "    print(f\"{'Attack Type':<20} {'Accuracy':<12} {'Correct':<10} {'Drop'}\")\n",
    "    print('-'*60)\n",
    "    \n",
    "    clean_acc = results['Clean (No Attack)']['accuracy']\n",
    "    for attack_name, result in results.items():\n",
    "        acc = result['accuracy']\n",
    "        drop = clean_acc - acc if attack_name != 'Clean (No Attack)' else 0\n",
    "        print(f\"{attack_name:<20} {acc:>6.1f}%      {result['correct']:>2}/{num_images}      {drop:>5.1f}%\")\n",
    "    print('='*60)\n",
    "    \n",
    "    # Visualize results\n",
    "    print('\\\\n Creating visualization...')\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(20, 8))\n",
    "    fig.suptitle('FedBN Adversarial Attack Visualization (First 5 Images)', fontsize=16, weight='bold')\n",
    "    \n",
    "    attack_names = list(attacks.keys())\n",
    "    num_to_show = 5\n",
    "    \n",
    "    for img_idx in range(num_to_show):\n",
    "        for attack_idx, attack_name in enumerate(attack_names):\n",
    "            ax = axes[attack_idx, img_idx]\n",
    "            \n",
    "            # Get image\n",
    "            img = adv_images_dict[attack_name][img_idx]\n",
    "            \n",
    "            # Denormalize\n",
    "            img_np = img.cpu().detach().numpy()\n",
    "            img_np = np.transpose(img_np, (1, 2, 0))\n",
    "            img_np = (img_np * 0.5) + 0.5\n",
    "            img_np = np.clip(img_np, 0, 1)\n",
    "            \n",
    "            # Get prediction\n",
    "            pred = results[attack_name]['predictions'][img_idx]\n",
    "            true_label = labels[img_idx].item()\n",
    "            \n",
    "            # Show image\n",
    "            ax.imshow(img_np)\n",
    "            ax.axis('off')\n",
    "            \n",
    "            # Title with color\n",
    "            if img_idx == 0:\n",
    "                title = f'{attack_name}\\\\nPred:{pred} True:{true_label}'\n",
    "            else:\n",
    "                title = f'Pred:{pred}\\\\nTrue:{true_label}'\n",
    "            \n",
    "            color = 'green' if pred == true_label else 'red'\n",
    "            ax.set_title(title, color=color, fontsize=9, weight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save visualization\n",
    "    os.makedirs(args.checkpoint_dir, exist_ok=True)\n",
    "    save_path = os.path.join(args.checkpoint_dir, 'quick_attack_test.png')\n",
    "    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "    print(f' Visualization saved: {save_path}')\n",
    "    plt.show()\n",
    "    \n",
    "    # Perturbation analysis\n",
    "    print('\\\\n' + '='*60)\n",
    "    print(' PERTURBATION ANALYSIS')\n",
    "    print('='*60)\n",
    "    \n",
    "    clean_img = images[0]\n",
    "    for attack_name in ['FGSM', 'PGD', 'CW']:\n",
    "        if attack_name in adv_images_dict:\n",
    "            adv_img = adv_images_dict[attack_name][0]\n",
    "            perturbation = (adv_img - clean_img).abs()\n",
    "            \n",
    "            print(f'\\\\n{attack_name}:')\n",
    "            print(f'   Mean perturbation: {perturbation.mean().item():.6f}')\n",
    "            print(f'   Max perturbation:  {perturbation.max().item():.6f}')\n",
    "            print(f'   L2 norm:           {torch.norm(perturbation).item():.6f}')\n",
    "    \n",
    "    print('\\\\n' + '='*60)\n",
    "    print(' Quick attack test completed!')\n",
    "    print('='*60)\n",
    "    \n",
    "    return results\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    quick_attack_test()\n",
    "\"\"\"\n",
    "\n",
    "with open(file_path, \"w\") as f:\n",
    "    f.write(new_code)\n",
    "\n",
    "print(\" quick_attack_test.py updated for FedBN!\")\n",
    "print(f\" File path: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!python /kaggle/working/FedBn-PyTorch/main.py"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
