{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ============================================================================\n# UNIFIED ATTACK EVALUATION - FedAvg, FedProx, FedBN\n# Three Attack Levels: Weak, Mid, Strong\n# ============================================================================\nprint(\"Installing dependencies...\")\nimport subprocess\nsubprocess.run([\"pip\", \"install\", \"medmnist\", \"--quiet\"], check=True)\nsubprocess.run([\"pip\", \"install\", \"git+https://github.com/openai/CLIP.git\", \"--quiet\"], check=True)\nsubprocess.run([\"pip\", \"install\", \"scikit-learn\", \"--quiet\"], check=True)\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms\nfrom medmnist.dataset import PathMNIST, TissueMNIST, OrganAMNIST, OCTMNIST\nimport clip\nfrom tqdm import tqdm\nimport json\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.metrics import precision_score, recall_score, f1_score, mean_squared_error\nimport os\nimport shutil\n\nprint(\"‚úÖ All dependencies loaded!\")\n\n# ============================================================================\n# CONFIGURATION - CHANGE ONLY THESE\n# ============================================================================\nATTACK_LEVEL = \"strong\"  # Options: \"weak\", \"mid\", \"strong\"\nDATASET_NAME = \"organamnist\"  # Options: \"pathmnist\", \"tissuemnist\", \"organamnist\", \"octmnist\"\nBATCH_SIZE = 32\n\n# Model checkpoint paths\nMODEL_PATHS = {\n    'fedavg': \"/kaggle/input/example/pytorch/default/1/Example/checkpoints_fedavg_organamnist/final_global_model.pth\",\n    'fedprox': \"/kaggle/input/example/pytorch/default/1/Example/checkpoints_fedprox_organamnist/final_global_model.pth\",\n    'fedbn': \"/kaggle/input/example3/pytorch/default/1/weight_history/fedbn/checkpoints_fedbn_pathmnist/final_global_model.pth\",\n    'fedper': \"/kaggle/input/example3/pytorch/default/1/weight_history/fedper/checkpoints_fedper_organamnist/final_global_model.pth\",\n}\n# ============================================================================\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Attack parameter configurations\nATTACK_LEVELS = {\n    'weak': {\n        'name': 'attack-level-weak',\n        'eps': 0.010,\n        'steps': 10,\n        'alpha': 0.0006\n    },\n    'mid': {\n        'name': 'attack-level-mid',\n        'eps': 0.030,\n        'steps': 10,\n        'alpha': 0.0010\n    },\n    'strong': {\n        'name': 'attack-level-strong',\n        'eps': 0.050,\n        'steps': 10,\n        'alpha': 0.0030\n    }\n}\n\n# Get current attack parameters\nattack_config = ATTACK_LEVELS[ATTACK_LEVEL]\nEPS = attack_config['eps']\nALPHA = attack_config['alpha']\nSTEPS = attack_config['steps']\nMAIN_DIR = f\"/kaggle/working/{attack_config['name']}(eps={EPS:.3f},alpha={ALPHA:.4f})\"\n\nprint(f\"\\n{'='*70}\")\nprint(f\" ATTACK CONFIGURATION: {ATTACK_LEVEL.upper()}\")\nprint('='*70)\nprint(f\"  Epsilon (eps):   {EPS}\")\nprint(f\"  Alpha:           {ALPHA}\")\nprint(f\"  Steps:           {STEPS}\")\nprint(f\"  Main Directory:  {MAIN_DIR}\")\nprint('='*70)\n\n# Dataset configurations\nDATASET_CONFIGS = {\n    'pathmnist': {\n        'num_classes': 9,\n        'class': PathMNIST,\n        'class_names': [\"adipose\", \"background\", \"debris\", \"lymphocytes\",\n                       \"mucus\", \"smooth muscle\", \"normal colon mucosa\",\n                       \"cancer-associated stroma\", \"colorectal adenocarcinoma epithelium\"]\n    },\n    'tissuemnist': {\n        'num_classes': 8,\n        'class': TissueMNIST,\n        'class_names': [\"collecting duct\", \"thick ascending limb\",\n                       \"distal convoluted tubule\", \"proximal tubule\",\n                       \"glomerular tuft\", \"blood vessel\", \"macula densa\",\n                       \"interstitial fibrosis\"]\n    },\n    'organamnist': {\n        'num_classes': 11,\n        'class': OrganAMNIST,\n        'class_names': [\"bladder\", \"femur-left\", \"femur-right\", \"heart\",\n                       \"kidneys\", \"liver\", \"lungs\", \"pancreas\",\n                       \"pelvis\", \"spleen\", \"kidney cyst\"]\n    },\n    'octmnist': {\n        'num_classes': 4,\n        'class': OCTMNIST,\n        'class_names': [\"choroidal neovascularization\", \"diabetic macular edema\",\n                       \"drusen\", \"normal\"]\n    }\n}\n\n# ============================================================================\n# MODEL ARCHITECTURES\n# ============================================================================\n\nclass CLIPFedPerClassifier(nn.Module):\n   \n    def __init__(self, num_classes, clip_model_name=\"ViT-B/32\", dropout=0.3, device='cuda'):\n        super(CLIPFedPerClassifier, self).__init__()\n        \n        self.num_classes = num_classes\n        self.dropout = dropout\n        \n        # Load pretrained CLIP model\n        self.clip_model, _ = clip.load(clip_model_name, device=device)\n        \n        # Get CLIP feature dimension\n        self.feature_dim = self.clip_model.visual.output_dim\n        \n        # Setup FedPer layer configuration\n        self._setup_fedper_layers()\n        \n        # Personalized MLP Head (NOT aggregated across clients)\n        # This is client-specific and remains local\n        self.head = nn.Sequential(\n            nn.Linear(self.feature_dim, 1024),\n            nn.BatchNorm1d(1024),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            \n            nn.Linear(1024, 512),\n            nn.BatchNorm1d(512),\n            nn.ReLU(),\n            nn.Dropout(dropout * 0.7),\n            \n            nn.Linear(512, 256),\n            nn.BatchNorm1d(256),\n            nn.ReLU(),\n            nn.Dropout(dropout * 0.5),\n            \n            nn.Linear(256, num_classes)\n        )\n        \n        self._initialize_weights()\n    \n    def _setup_fedper_layers(self):\n      \n        # Freeze all CLIP parameters first\n        for param in self.clip_model.parameters():\n            param.requires_grad = False\n        \n        # Unfreeze last 2 transformer blocks (SHARED layers for aggregation)\n        if hasattr(self.clip_model.visual, 'transformer'):\n            num_blocks = len(self.clip_model.visual.transformer.resblocks)\n            num_shared = 2  # Last 2 blocks are shared\n            \n            for block in self.clip_model.visual.transformer.resblocks[-num_shared:]:\n                for param in block.parameters():\n                    param.requires_grad = True\n        \n        # Also unfreeze final projection layer (shared)\n        if hasattr(self.clip_model.visual, 'proj') and self.clip_model.visual.proj is not None:\n            self.clip_model.visual.proj.requires_grad = True\n    \n    def _initialize_weights(self):\n       \n        for m in self.head.modules():\n            if isinstance(m, nn.Linear):\n                nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='relu')\n                if m.bias is not None:\n                    nn.init.constant_(m.bias, 0)\n            elif isinstance(m, nn.BatchNorm1d):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n    \n    def forward(self, images):\n      \n        # CLIP feature extraction (last 2 blocks are trainable)\n        image_features = self.clip_model.encode_image(images)\n        image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n        image_features = image_features.float()\n        \n        # Personalized classification head\n        logits = self.head(image_features)\n        return logits\n    \n    def get_shared_params(self):\n       \n        shared_params = []\n        for param in self.clip_model.parameters():\n            if param.requires_grad:\n                shared_params.append(param)\n        return shared_params\n    \n    def get_personalized_params(self):\n      \n        return [p for p in self.head.parameters() if p.requires_grad]\n    \n    def get_trainable_params(self):\n       \n        return [p for p in self.parameters() if p.requires_grad]\n\n\nclass CLIPFedAvgClassifier(nn.Module):\n    \"\"\"FedAvg: CLIP + Text-based Classification\"\"\"\n    def __init__(self, num_classes, device, class_names):\n        super().__init__()\n        self.clip_model, _ = clip.load(\"ViT-B/32\", device=device)\n        self.num_classes = num_classes\n        \n        # Freeze text encoder\n        for param in self.clip_model.transformer.parameters():\n            param.requires_grad = False\n        for param in self.clip_model.token_embedding.parameters():\n            param.requires_grad = False\n        for param in self.clip_model.ln_final.parameters():\n            param.requires_grad = False\n        self.clip_model.positional_embedding.requires_grad = False\n        self.clip_model.text_projection.requires_grad = False\n        \n        # Register text features\n        if class_names:\n            with torch.no_grad():\n                text_tokens = clip.tokenize([f\"a microscopic image of {c}\" for c in class_names]).to(device)\n                text_features = self.clip_model.encode_text(text_tokens)\n                text_features /= text_features.norm(dim=-1, keepdim=True)\n            self.register_buffer('text_features', text_features)\n    \n    def forward(self, images):\n        image_features = self.clip_model.encode_image(images)\n        image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n        return 100.0 * image_features @ self.text_features.T\n\n\nclass CLIPFedProxClassifier(nn.Module):\n    \"\"\"FedProx: CLIP + Trainable Head\"\"\"\n    def __init__(self, num_classes, clip_model_name=\"ViT-B/32\", dropout=0.5):\n        super().__init__()\n        self.clip_model, _ = clip.load(clip_model_name, device=device)\n        \n        # Freeze CLIP\n        for param in self.clip_model.parameters():\n            param.requires_grad = False\n        \n        feature_dim = self.clip_model.visual.output_dim\n        \n        # Trainable head\n        self.head = nn.Sequential(\n            nn.Linear(feature_dim, 1024),\n            nn.BatchNorm1d(1024),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            \n            nn.Linear(1024, 512),\n            nn.BatchNorm1d(512),\n            nn.ReLU(),\n            nn.Dropout(dropout * 0.7),\n            \n            nn.Linear(512, 256),\n            nn.BatchNorm1d(256),\n            nn.ReLU(),\n            nn.Dropout(dropout * 0.5),\n            \n            nn.Linear(256, num_classes)\n        )\n    \n    def forward(self, images):\n        with torch.no_grad():\n            feats = self.clip_model.encode_image(images)\n            feats = feats / feats.norm(dim=-1, keepdim=True)\n        feats = feats.float()\n        return self.head(feats)\n\n\nclass CLIPFedBNClassifier(nn.Module):\n    \"\"\"FedBN: CLIP + Simple Head with BN\"\"\"\n    def __init__(self, num_classes, clip_model_name=\"ViT-B/32\", dropout=0.5):\n        super().__init__()\n        self.clip_model, _ = clip.load(clip_model_name, device=device)\n        \n        # Freeze CLIP\n        for param in self.clip_model.parameters():\n            param.requires_grad = False\n        \n        feature_dim = self.clip_model.visual.output_dim\n        \n        self.fc1 = nn.Linear(feature_dim, 256)\n        self.bn1 = nn.BatchNorm1d(256)\n        self.fc2 = nn.Linear(256, num_classes)\n        self.bn2 = nn.BatchNorm1d(num_classes)\n        self.relu = nn.ReLU()\n        self.drop = nn.Dropout(dropout)\n    \n    def forward(self, x):\n        with torch.no_grad():\n            img_feat = self.clip_model.encode_image(x).float()\n        x = self.fc1(img_feat)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.drop(x)\n        x = self.fc2(x)\n        x = self.bn2(x)\n        return x\n\n\n# ============================================================================\n# ATTACK FUNCTIONS \n# ============================================================================\n\n\n\nclass AttackableWrapper(nn.Module):\n    \"\"\"Wrapper to bypass torch.no_grad() context in model forward\"\"\"\n    def __init__(self, model, model_type):\n        super().__init__()\n        self.model = model\n        self.model_type = model_type\n        \n        # Store original gradient states\n        self.original_grad_states = {}\n        \n        # Enable gradients based on model type\n        if model_type == 'fedprox':\n            for name, param in self.model.clip_model.visual.named_parameters():\n                self.original_grad_states[f'visual.{name}'] = param.requires_grad\n                param.requires_grad = True\n            for name, param in self.model.head.named_parameters():\n                self.original_grad_states[f'head.{name}'] = param.requires_grad\n                param.requires_grad = True\n                \n        elif model_type == 'fedbn':\n            for name, param in self.model.clip_model.visual.named_parameters():\n                self.original_grad_states[f'visual.{name}'] = param.requires_grad\n                param.requires_grad = True\n            for name, param in self.model.fc1.named_parameters():\n                self.original_grad_states[f'fc1.{name}'] = param.requires_grad\n                param.requires_grad = True\n            for name, param in self.model.fc2.named_parameters():\n                self.original_grad_states[f'fc2.{name}'] = param.requires_grad\n                param.requires_grad = True\n                \n        elif model_type == 'fedavg':\n            for name, param in self.model.clip_model.visual.named_parameters():\n                self.original_grad_states[f'visual.{name}'] = param.requires_grad\n                param.requires_grad = True\n    \n    def forward(self, x):\n        \"\"\"Forward pass WITHOUT torch.no_grad() context\"\"\"\n        if self.model_type == 'fedprox':\n            # Manual forward to bypass no_grad\n            feats = self.model.clip_model.encode_image(x)\n            feats = feats / feats.norm(dim=-1, keepdim=True)\n            feats = feats.float()\n            return self.model.head(feats)\n            \n        elif self.model_type == 'fedbn':\n            # Manual forward to bypass no_grad\n            img_feat = self.model.clip_model.encode_image(x).float()\n            x = self.model.fc1(img_feat)\n            x = self.model.bn1(x)\n            x = self.model.relu(x)\n            x = self.model.drop(x)\n            x = self.model.fc2(x)\n            x = self.model.bn2(x)\n            return x\n            \n        elif self.model_type == 'fedavg':\n            # FedAvg uses text features\n            image_features = self.model.clip_model.encode_image(x)\n            image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n            return 100.0 * image_features @ self.model.text_features.T\n        \n        else:\n            return self.model(x)\n    \n    def restore_frozen_state(self):\n        \"\"\"Restore original frozen state after attack\"\"\"\n        if self.model_type == 'fedprox':\n            for name, param in self.model.clip_model.visual.named_parameters():\n                key = f'visual.{name}'\n                if key in self.original_grad_states:\n                    param.requires_grad = self.original_grad_states[key]\n            for name, param in self.model.head.named_parameters():\n                key = f'head.{name}'\n                if key in self.original_grad_states:\n                    param.requires_grad = self.original_grad_states[key]\n                    \n        elif self.model_type == 'fedbn':\n            for name, param in self.model.clip_model.visual.named_parameters():\n                key = f'visual.{name}'\n                if key in self.original_grad_states:\n                    param.requires_grad = self.original_grad_states[key]\n            for name, param in self.model.fc1.named_parameters():\n                key = f'fc1.{name}'\n                if key in self.original_grad_states:\n                    param.requires_grad = self.original_grad_states[key]\n            for name, param in self.model.fc2.named_parameters():\n                key = f'fc2.{name}'\n                if key in self.original_grad_states:\n                    param.requires_grad = self.original_grad_states[key]\n                    \n        elif self.model_type == 'fedavg':\n            for name, param in self.model.clip_model.visual.named_parameters():\n                key = f'visual.{name}'\n                if key in self.original_grad_states:\n                    param.requires_grad = self.original_grad_states[key]\n\n\ndef fgsm_attack(model, x, y, model_type, eps):\n    \"\"\"FGSM Attack - CORRECTED\"\"\"\n    attack_model = AttackableWrapper(model, model_type)\n    attack_model.train()\n    \n    x_adv = x.clone().detach().requires_grad_(True)\n    \n    # Forward pass\n    outputs = attack_model(x_adv)\n    loss = F.cross_entropy(outputs, y)\n    \n    # Backward pass\n    attack_model.zero_grad()\n    if x_adv.grad is not None:\n        x_adv.grad.zero_()\n    \n    loss.backward()\n    \n    # Check gradient\n    if x_adv.grad is None:\n        attack_model.restore_frozen_state()\n        return x.detach()\n    \n    # Generate adversarial example\n    with torch.no_grad():\n        grad_sign = x_adv.grad.sign()\n        x_adv = x + eps * grad_sign\n        x_adv = torch.clamp(x_adv, -1, 1)\n    \n    # Restore frozen state\n    attack_model.restore_frozen_state()\n    \n    return x_adv.detach()\n\n\ndef pgd_attack(model, x, y, model_type, eps, alpha, steps):\n    \"\"\"PGD Attack - CORRECTED\"\"\"\n    attack_model = AttackableWrapper(model, model_type)\n    \n    # Random initialization\n    with torch.no_grad():\n        delta = torch.empty_like(x).uniform_(-eps, eps)\n        x_adv = torch.clamp(x + delta, -1, 1)\n    \n    for step in range(steps):\n        attack_model.train()\n        x_adv = x_adv.clone().detach().requires_grad_(True)\n        \n        # Forward pass\n        outputs = attack_model(x_adv)\n        loss = F.cross_entropy(outputs, y)\n        \n        # Backward pass\n        attack_model.zero_grad()\n        if x_adv.grad is not None:\n            x_adv.grad.zero_()\n        \n        loss.backward()\n        \n        if x_adv.grad is None:\n            break\n        \n        # Update adversarial example\n        with torch.no_grad():\n            grad_sign = x_adv.grad.sign()\n            x_adv = x_adv + alpha * grad_sign\n            \n            # Project back to epsilon ball\n            eta = torch.clamp(x_adv - x, -eps, eps)\n            x_adv = torch.clamp(x + eta, -1, 1)\n    \n    # Restore frozen state\n    attack_model.restore_frozen_state()\n    \n    return x_adv.detach()\n\n\ndef bim_attack(model, x, y, model_type, eps, alpha, steps):\n    \"\"\"BIM Attack - CORRECTED\"\"\"\n    attack_model = AttackableWrapper(model, model_type)\n    x_adv = x.clone().detach()\n    \n    for step in range(steps):\n        attack_model.train()\n        x_adv = x_adv.clone().detach().requires_grad_(True)\n        \n        # Forward pass\n        outputs = attack_model(x_adv)\n        loss = F.cross_entropy(outputs, y)\n        \n        # Backward pass\n        attack_model.zero_grad()\n        if x_adv.grad is not None:\n            x_adv.grad.zero_()\n        \n        loss.backward()\n        \n        if x_adv.grad is None:\n            break\n        \n        # Update adversarial example\n        with torch.no_grad():\n            grad_sign = x_adv.grad.sign()\n            x_adv = x_adv + alpha * grad_sign\n            \n            # Project back to epsilon ball\n            eta = torch.clamp(x_adv - x, -eps, eps)\n            x_adv = torch.clamp(x + eta, -1, 1)\n    \n    # Restore frozen state\n    attack_model.restore_frozen_state()\n    \n    return x_adv.detach()\n\n\ndef mifgsm_attack(model, x, y, model_type, eps, alpha, steps, decay=1.0):\n    \"\"\"MI-FGSM Attack - CORRECTED\"\"\"\n    attack_model = AttackableWrapper(model, model_type)\n    momentum = torch.zeros_like(x)\n    x_adv = x.clone().detach()\n    \n    for step in range(steps):\n        attack_model.train()\n        x_adv = x_adv.clone().detach().requires_grad_(True)\n        \n        # Forward pass\n        outputs = attack_model(x_adv)\n        loss = F.cross_entropy(outputs, y)\n        \n        # Backward pass\n        attack_model.zero_grad()\n        if x_adv.grad is not None:\n            x_adv.grad.zero_()\n        \n        loss.backward()\n        \n        if x_adv.grad is None:\n            break\n        \n        # Update momentum\n        grad = x_adv.grad.data\n        grad_norm = grad / (torch.mean(torch.abs(grad), dim=(1,2,3), keepdim=True) + 1e-8)\n        momentum = decay * momentum + grad_norm\n        \n        # Update adversarial example\n        with torch.no_grad():\n            x_adv = x_adv + alpha * momentum.sign()\n            \n            # Project back to epsilon ball\n            eta = torch.clamp(x_adv - x, -eps, eps)\n            x_adv = torch.clamp(x + eta, -1, 1)\n    \n    # Restore frozen state\n    attack_model.restore_frozen_state()\n    \n    return x_adv.detach()\n\n# ============================================================================\n# EVALUATION FUNCTION\n# ============================================================================\n\ndef evaluate_model_with_attacks(model, test_loader, model_type, num_classes):\n    \"\"\"Evaluate a model with all attacks\"\"\"\n    \n    attacks = {\n        'FGSM': lambda x, y: fgsm_attack(model, x, y, model_type, EPS),\n        'PGD': lambda x, y: pgd_attack(model, x, y, model_type, EPS, ALPHA, STEPS),\n        'BIM': lambda x, y: bim_attack(model, x, y, model_type, EPS, ALPHA, STEPS),\n        'MI-FGSM': lambda x, y: mifgsm_attack(model, x, y, model_type, EPS, ALPHA, STEPS),\n        \n    }\n    \n    results = []\n    \n    for attack_name, attack_fn in attacks.items():\n        print(f\"\\n  [{attack_name}]\")\n        \n        clean_preds, clean_labels = [], []\n        adv_preds, adv_labels = [], []\n        clean_probs, adv_probs = [], []\n        \n        for imgs, lbls in tqdm(test_loader, desc=f\"    {attack_name:12s}\", ncols=100, leave=False):\n            imgs, lbls = imgs.to(device), lbls.to(device).squeeze()\n            \n            # Clean predictions\n            model.eval()\n            with torch.no_grad():\n                outputs = model(imgs)\n                probs = F.softmax(outputs, dim=1)\n                preds = outputs.max(1)[1]\n                clean_preds.extend(preds.cpu().numpy())\n                clean_labels.extend(lbls.cpu().numpy())\n                clean_probs.extend(probs.cpu().numpy())\n            \n            # Adversarial predictions\n            try:\n                adv_imgs = attack_fn(imgs, lbls)\n                model.eval()\n                with torch.no_grad():\n                    outputs = model(adv_imgs)\n                    probs = F.softmax(outputs, dim=1)\n                    preds = outputs.max(1)[1]\n                    adv_preds.extend(preds.cpu().numpy())\n                    adv_labels.extend(lbls.cpu().numpy())\n                    adv_probs.extend(probs.cpu().numpy())\n            except Exception as e:\n                adv_preds.extend(clean_preds[-len(lbls):])\n                adv_labels.extend(lbls.cpu().numpy())\n                adv_probs.extend(clean_probs[-len(lbls):])\n        \n        # Calculate metrics\n        clean_preds = np.array(clean_preds)\n        clean_labels = np.array(clean_labels)\n        adv_preds = np.array(adv_preds)\n        adv_labels = np.array(adv_labels)\n        clean_probs = np.array(clean_probs)\n        adv_probs = np.array(adv_probs)\n        \n        # Accuracy\n        clean_acc = 100 * (clean_preds == clean_labels).mean()\n        adv_acc = 100 * (adv_preds == adv_labels).mean()\n        asr = 100 * (clean_preds != adv_preds).mean()\n        \n        # Precision\n        clean_prec = 100 * precision_score(clean_labels, clean_preds, average='weighted', zero_division=0)\n        adv_prec = 100 * precision_score(adv_labels, adv_preds, average='weighted', zero_division=0)\n        \n        # Recall\n        clean_rec = 100 * recall_score(clean_labels, clean_preds, average='weighted', zero_division=0)\n        adv_rec = 100 * recall_score(adv_labels, adv_preds, average='weighted', zero_division=0)\n        \n        # F1-Score\n        clean_f1 = 100 * f1_score(clean_labels, clean_preds, average='weighted', zero_division=0)\n        adv_f1 = 100 * f1_score(adv_labels, adv_preds, average='weighted', zero_division=0)\n        \n        # RMSE\n        clean_rmse = np.sqrt(mean_squared_error(\n            np.eye(num_classes)[clean_labels], clean_probs\n        ))\n        adv_rmse = np.sqrt(mean_squared_error(\n            np.eye(num_classes)[adv_labels], adv_probs\n        ))\n        \n        print(f\"    Clean: {clean_acc:.2f}% | Adv: {adv_acc:.2f}% | ASR: {asr:.2f}%\")\n        \n        results.append({\n            'attack': attack_name,\n            'clean_metrics': {\n                'accuracy': round(clean_acc, 2),\n                'precision': round(clean_prec, 2),\n                'recall': round(clean_rec, 2),\n                'f1_score': round(clean_f1, 2),\n                'rmse': round(clean_rmse, 4)\n            },\n            'adversarial_metrics': {\n                'accuracy': round(adv_acc, 2),\n                'precision': round(adv_prec, 2),\n                'recall': round(adv_rec, 2),\n                'f1_score': round(adv_f1, 2),\n                'rmse': round(adv_rmse, 4)\n            },\n            'attack_success_rate': round(asr, 2)\n        })\n    \n    return results\n\n\n# ============================================================================\n# VISUALIZATION\n# ============================================================================\n\ndef create_visualization(results, save_path, model_name):\n    \"\"\"Create comprehensive visualization\"\"\"\n    fig = plt.figure(figsize=(18, 12))\n    gs = fig.add_gridspec(3, 3, hspace=0.35, wspace=0.35)\n    fig.suptitle(f'{model_name.upper()} - Attack Evaluation (eps={EPS}, alpha={ALPHA})', \n                 fontsize=16, fontweight='bold')\n    \n    names = [r['attack'] for r in results]\n    x = np.arange(len(names))\n    \n    # Plot 1: Accuracy\n    ax = fig.add_subplot(gs[0, 0])\n    clean_acc = [r['clean_metrics']['accuracy'] for r in results]\n    adv_acc = [r['adversarial_metrics']['accuracy'] for r in results]\n    ax.bar(x - 0.2, clean_acc, 0.4, label='Clean', color='#2ecc71', alpha=0.8)\n    ax.bar(x + 0.2, adv_acc, 0.4, label='Adversarial', color='#e74c3c', alpha=0.8)\n    ax.set_ylabel('Accuracy (%)', fontweight='bold')\n    ax.set_title('Accuracy Comparison')\n    ax.set_xticks(x)\n    ax.set_xticklabels(names, rotation=15, ha='right')\n    ax.legend()\n    ax.grid(alpha=0.3, axis='y')\n    \n    # Plot 2: Precision\n    ax = fig.add_subplot(gs[0, 1])\n    clean_prec = [r['clean_metrics']['precision'] for r in results]\n    adv_prec = [r['adversarial_metrics']['precision'] for r in results]\n    ax.bar(x - 0.2, clean_prec, 0.4, label='Clean', color='#3498db', alpha=0.8)\n    ax.bar(x + 0.2, adv_prec, 0.4, label='Adversarial', color='#e67e22', alpha=0.8)\n    ax.set_ylabel('Precision (%)', fontweight='bold')\n    ax.set_title('Precision Comparison')\n    ax.set_xticks(x)\n    ax.set_xticklabels(names, rotation=15, ha='right')\n    ax.legend()\n    ax.grid(alpha=0.3, axis='y')\n    \n    # Plot 3: Recall\n    ax = fig.add_subplot(gs[0, 2])\n    clean_rec = [r['clean_metrics']['recall'] for r in results]\n    adv_rec = [r['adversarial_metrics']['recall'] for r in results]\n    ax.bar(x - 0.2, clean_rec, 0.4, label='Clean', color='#9b59b6', alpha=0.8)\n    ax.bar(x + 0.2, adv_rec, 0.4, label='Adversarial', color='#34495e', alpha=0.8)\n    ax.set_ylabel('Recall (%)', fontweight='bold')\n    ax.set_title('Recall Comparison')\n    ax.set_xticks(x)\n    ax.set_xticklabels(names, rotation=15, ha='right')\n    ax.legend()\n    ax.grid(alpha=0.3, axis='y')\n    \n    # Plot 4: F1-Score\n    ax = fig.add_subplot(gs[1, 0])\n    clean_f1 = [r['clean_metrics']['f1_score'] for r in results]\n    adv_f1 = [r['adversarial_metrics']['f1_score'] for r in results]\n    ax.bar(x - 0.2, clean_f1, 0.4, label='Clean', color='#1abc9c', alpha=0.8)\n    ax.bar(x + 0.2, adv_f1, 0.4, label='Adversarial', color='#c0392b', alpha=0.8)\n    ax.set_ylabel('F1-Score (%)', fontweight='bold')\n    ax.set_title('F1-Score Comparison')\n    ax.set_xticks(x)\n    ax.set_xticklabels(names, rotation=15, ha='right')\n    ax.legend()\n    ax.grid(alpha=0.3, axis='y')\n    \n    # Plot 5: RMSE\n    ax = fig.add_subplot(gs[1, 1])\n    clean_rmse = [r['clean_metrics']['rmse'] for r in results]\n    adv_rmse = [r['adversarial_metrics']['rmse'] for r in results]\n    ax.bar(x - 0.2, clean_rmse, 0.4, label='Clean', color='#f39c12', alpha=0.8)\n    ax.bar(x + 0.2, adv_rmse, 0.4, label='Adversarial', color='#d35400', alpha=0.8)\n    ax.set_ylabel('RMSE', fontweight='bold')\n    ax.set_title('RMSE Comparison')\n    ax.set_xticks(x)\n    ax.set_xticklabels(names, rotation=15, ha='right')\n    ax.legend()\n    ax.grid(alpha=0.3, axis='y')\n    \n    # Plot 6: Attack Success Rate\n    ax = fig.add_subplot(gs[1, 2])\n    asr = [r['attack_success_rate'] for r in results]\n    ax.bar(names, asr, color=['#e74c3c', '#e67e22', '#f39c12', '#d35400'], alpha=0.8)\n    ax.set_ylabel('ASR (%)', fontweight='bold')\n    ax.set_title('Attack Success Rate')\n    ax.set_xticklabels(names, rotation=15, ha='right')\n    ax.grid(alpha=0.3, axis='y')\n    \n    # Plot 7-9: Metric Degradation\n    metrics_to_plot = [\n        ('accuracy', 'Accuracy Drop', gs[2, 0], '#e74c3c'),\n        ('precision', 'Precision Drop', gs[2, 1], '#3498db'),\n        ('f1_score', 'F1-Score Drop', gs[2, 2], '#9b59b6')\n    ]\n    \n    for metric, title, position, color in metrics_to_plot:\n        ax = fig.add_subplot(position)\n        drops = [r['clean_metrics'][metric] - r['adversarial_metrics'][metric] for r in results]\n        ax.bar(names, drops, color=color, alpha=0.8)\n        ax.set_ylabel('Drop (%)', fontweight='bold')\n        ax.set_title(title)\n        ax.set_xticklabels(names, rotation=15, ha='right')\n        ax.grid(alpha=0.3, axis='y')\n        ax.axhline(y=0, color='black', linestyle='--', linewidth=0.8, alpha=0.5)\n    \n    plt.tight_layout()\n    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n    plt.close()\n\n\n# ============================================================================\n# MAIN EXECUTION\n# ============================================================================\n\ndef main():\n    \"\"\"Main execution function\"\"\"\n    \n    os.makedirs(MAIN_DIR, exist_ok=True)\n    data_root = '/kaggle/working/medmnist_data'\n    os.makedirs(data_root, exist_ok=True)\n    \n    # Load dataset\n    print(f\"\\n{'='*70}\")\n    print(\" LOADING DATASET\")\n    print('='*70)\n    \n    config = DATASET_CONFIGS[DATASET_NAME.lower()]\n    transform = transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.Grayscale(num_output_channels=3),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n    ])\n    \n    test_dataset = config['class'](root=data_root, split='test', \n                                    download=True, transform=transform)\n    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n    \n    print(f\"‚úÖ Loaded {len(test_dataset)} test samples | Classes: {config['num_classes']}\")\n    \n    # Model configurations\n    model_configs = {\n    'fedprox': {\n        'class': CLIPFedProxClassifier,\n        'init_args': {\n            'num_classes': config['num_classes'],\n            'dropout': 0.5\n        }\n    },\n\n     'fedbn': {\n         'class': CLIPFedBNClassifier,\n         'init_args': {\n             'num_classes': config['num_classes'],\n             'dropout': 0.5\n         }\n     },\n\n     'fedavg': {\n        'class': CLIPFedAvgClassifier,\n         'init_args': {\n             'num_classes': config['num_classes'],\n             'device': device,\n            'class_names': config['class_names']\n        }\n     },\n\n    'fedper': {\n        'class': CLIPFedPerClassifier,\n        'init_args': {\n            'num_classes': config['num_classes'],\n            'dropout': 0.3,\n            'device': device\n        }\n     }\n}\n\n    \n    all_results = {}\n    \n    for model_name in [ 'fedprox','fedper','fedpbn','fedpavg']:\n        print(f\"\\n{'='*70}\")\n        print(f\" EVALUATING: {model_name.upper()}\")\n        print('='*70)\n        \n        # Check if model path exists\n        if not os.path.exists(MODEL_PATHS[model_name]):\n            print(f\"‚ö†Ô∏è  Model not found: {MODEL_PATHS[model_name]}\")\n            print(f\"   Skipping {model_name}...\")\n            continue\n        \n        try:\n            # Load model\n            model_config = model_configs[model_name]\n            model = model_config['class'](**model_config['init_args'])\n            \n            checkpoint = torch.load(MODEL_PATHS[model_name], map_location=device)\n            if isinstance(checkpoint, dict):\n                if 'server_state_dict' in checkpoint:\n                    state_dict = checkpoint['server_state_dict']\n                elif 'model_state_dict' in checkpoint:\n                    state_dict = checkpoint['model_state_dict']\n                else:\n                    state_dict = checkpoint\n            else:\n                state_dict = checkpoint\n            \n            model.load_state_dict(state_dict, strict=False)\n            model.to(device)\n            model.eval()\n            \n            print(f\"‚úÖ {model_name.upper()} model loaded successfully\")\n            \n            # Run attacks\n            results = evaluate_model_with_attacks(model, test_loader, model_name, config['num_classes'])\n            all_results[model_name] = results\n            \n            # Save results\n            save_dir = os.path.join(MAIN_DIR, f\"{model_name}_{DATASET_NAME}_attack_results\")\n            os.makedirs(save_dir, exist_ok=True)\n            \n            # Save JSON\n            with open(f\"{save_dir}/attack_results.json\", 'w') as f:\n                json.dump(results, f, indent=2)\n            \n            # Create visualization\n            create_visualization(results, f\"{save_dir}/attack_results.png\", model_name)\n            \n            # Print summary\n            print(f\"\\n  DETAILED SUMMARY:\")\n            print(f\"  {'-'*90}\")\n            print(f\"  {'Attack':<12} | {'Clean':<40} | {'Adversarial':<40}\")\n            print(f\"  {'-'*90}\")\n            for r in results:\n                clean_str = f\"Acc:{r['clean_metrics']['accuracy']:>5.1f}% Prec:{r['clean_metrics']['precision']:>5.1f}% Rec:{r['clean_metrics']['recall']:>5.1f}% F1:{r['clean_metrics']['f1_score']:>5.1f}%\"\n                adv_str = f\"Acc:{r['adversarial_metrics']['accuracy']:>5.1f}% Prec:{r['adversarial_metrics']['precision']:>5.1f}% Rec:{r['adversarial_metrics']['recall']:>5.1f}% F1:{r['adversarial_metrics']['f1_score']:>5.1f}%\"\n                print(f\"  {r['attack']:<12} | {clean_str:<40} | {adv_str:<40}\")\n            print(f\"  {'-'*90}\")\n            print(f\"\\n  {'Attack':<12} | {'ASR':>8} | {'Clean RMSE':>12} | {'Adv RMSE':>12}\")\n            print(f\"  {'-'*50}\")\n            for r in results:\n                print(f\"  {r['attack']:<12} | {r['attack_success_rate']:>7.2f}% | {r['clean_metrics']['rmse']:>12.4f} | {r['adversarial_metrics']['rmse']:>12.4f}\")\n            print(f\"  {'-'*50}\")\n            \n            print(f\"\\n  ‚úÖ Results saved to: {save_dir}/\")\n            \n            # Clean up\n            del model\n            torch.cuda.empty_cache()\n            \n        except Exception as e:\n            print(f\"‚ùå Error evaluating {model_name}: {e}\")\n            continue\n    \n    # Final summary\n    print(f\"\\n{'='*70}\")\n    print(\" EVALUATION COMPLETE!\")\n    print('='*70)\n    print(f\"üìÅ All results saved in: {MAIN_DIR}/\")\n    print(f\"\\nProcessed models: {', '.join(all_results.keys())}\")\n    print('='*70)\n\n\nif __name__ == \"__main__\":\n    main()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null}]}