{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":670237,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":507599,"modelId":522298}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ============================================================================\n# COMPLETE STANDALONE ATTACK EVALUATION - SINGLE CELL\n# ============================================================================\nprint(\"Installing dependencies...\")\nimport subprocess\nimport os\n\n# Install\nsubprocess.run([\"pip\", \"install\", \"medmnist\", \"--quiet\"], check=True)\nsubprocess.run([\"pip\", \"install\", \"git+https://github.com/openai/CLIP.git\", \"--quiet\"], check=True)\n\n# Now import everything\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms\nfrom medmnist.dataset import PathMNIST, TissueMNIST, OrganAMNIST, OCTMNIST\nimport clip\nfrom tqdm import tqdm\nimport json\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nprint(\"✅ All dependencies loaded!\")\n\n# ========================================\n# CONFIGURATION - CHANGE THESE\n# ========================================\nMODEL_PATH = \"/kaggle/input/example/pytorch/default/1/Example/checkpoints_fedavg_organamnist/final_global_model.pth\"\nDATASET_NAME = \"organamnist\"\nBATCH_SIZE = 32\nSAVE_DIR = \"/kaggle/working/attack_results\"\n# ========================================\n\nos.makedirs('./data/medmnist', exist_ok=True)\nos.makedirs(SAVE_DIR, exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Dataset configs\nDATASET_CONFIGS = {\n    'pathmnist': {\n        'num_classes': 9,\n        'class': PathMNIST,\n        'class_names': [\"adipose\", \"background\", \"debris\", \"lymphocytes\",\n                       \"mucus\", \"smooth muscle\", \"normal colon mucosa\",\n                       \"cancer-associated stroma\", \"colorectal adenocarcinoma epithelium\"]\n    },\n    'tissuemnist': {\n        'num_classes': 8,\n        'class': TissueMNIST,\n        'class_names': [\"collecting duct\", \"thick ascending limb\",\n                       \"distal convoluted tubule\", \"proximal tubule\",\n                       \"glomerular tuft\", \"blood vessel\", \"macula densa\",\n                       \"interstitial fibrosis\"]\n    },\n    'organamnist': {\n        'num_classes': 11,\n        'class': OrganAMNIST,\n        'class_names': [\"bladder\", \"femur-left\", \"femur-right\", \"heart\",\n                       \"kidneys\", \"liver\", \"lungs\", \"pancreas\",\n                       \"pelvis\", \"spleen\", \"kidney cyst\"]\n    },\n    'octmnist': {\n        'num_classes': 4,\n        'class': OCTMNIST,\n        'class_names': [\"choroidal neovascularization\", \"diabetic macular edema\",\n                       \"drusen\", \"normal\"]\n    }\n}\n\n# Model class\nclass CLIPMedMNISTClassifier(nn.Module):\n    def __init__(self, num_classes, device, class_names=None):\n        super(CLIPMedMNISTClassifier, self).__init__()\n        self.clip_model, _ = clip.load(\"ViT-B/32\", device=device)\n        self.num_classes = num_classes\n        \n        for param in self.clip_model.transformer.parameters():\n            param.requires_grad = False\n        for param in self.clip_model.token_embedding.parameters():\n            param.requires_grad = False\n        for param in self.clip_model.ln_final.parameters():\n            param.requires_grad = False\n        self.clip_model.positional_embedding.requires_grad = False\n        self.clip_model.text_projection.requires_grad = False\n        \n        if class_names:\n            with torch.no_grad():\n                text_tokens = clip.tokenize([f\"a microscopic image of {c}\" for c in class_names]).to(device)\n                text_features = self.clip_model.encode_text(text_tokens)\n                text_features /= text_features.norm(dim=-1, keepdim=True)\n            self.register_buffer('text_features', text_features)\n    \n    def forward(self, images):\n        image_features = self.clip_model.encode_image(images)\n        image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n        return 100.0 * image_features @ self.text_features.T\n\n# Attack functions\ndef fgsm(model, x, y, device, eps=0.03):\n    x = x.clone().detach().requires_grad_(True)\n    out = model(x)\n    out = out.logits if hasattr(out, 'logits') else out\n    loss = F.cross_entropy(out, y)\n    loss.backward()\n    return torch.clamp(x + eps * x.grad.sign(), -1, 1).detach()\n\ndef pgd(model, x, y, device, eps=0.03, alpha=0.01, steps=10):\n    x_adv = x + torch.empty_like(x).uniform_(-eps, eps)\n    x_adv = torch.clamp(x_adv, -1, 1)\n    for _ in range(steps):\n        x_adv.requires_grad_(True)\n        out = model(x_adv)\n        out = out.logits if hasattr(out, 'logits') else out\n        loss = F.cross_entropy(out, y)\n        loss.backward()\n        x_adv = x_adv.detach() + alpha * x_adv.grad.sign()\n        x_adv = torch.clamp(x_adv, x - eps, x + eps)\n        x_adv = torch.clamp(x_adv, -1, 1)\n    return x_adv.detach()\n\ndef bim(model, x, y, device, eps=0.03, alpha=0.01, steps=10):\n    x_adv = x.clone()\n    for _ in range(steps):\n        x_adv.requires_grad_(True)\n        out = model(x_adv)\n        out = out.logits if hasattr(out, 'logits') else out\n        loss = F.cross_entropy(out, y)\n        loss.backward()\n        x_adv = x_adv.detach() + alpha * x_adv.grad.sign()\n        x_adv = torch.clamp(x_adv, x - eps, x + eps)\n        x_adv = torch.clamp(x_adv, -1, 1)\n    return x_adv.detach()\n\ndef mifgsm(model, x, y, device, eps=0.03, alpha=0.01, steps=10, decay=1.0):\n    momentum = torch.zeros_like(x).to(device)\n    x_adv = x.clone()\n    for _ in range(steps):\n        x_adv.requires_grad_(True)\n        out = model(x_adv)\n        out = out.logits if hasattr(out, 'logits') else out\n        loss = F.cross_entropy(out, y)\n        loss.backward()\n        grad = x_adv.grad.data\n        grad = grad / (torch.mean(torch.abs(grad), dim=(1,2,3), keepdim=True) + 1e-8)\n        momentum = decay * momentum + grad\n        x_adv = x_adv.detach() + alpha * momentum.sign()\n        x_adv = torch.clamp(x_adv, x - eps, x + eps)\n        x_adv = torch.clamp(x_adv, -1, 1)\n    return x_adv.detach()\n\ndef deepfool(model, x, y, device, steps=30):\n    perturbed = x.clone()\n    for idx in range(x.size(0)):\n        img = x[idx:idx+1].clone()\n        pert = img.clone()\n        for _ in range(steps):\n            pert.requires_grad_(True)\n            out = model(pert)\n            out = out.logits if hasattr(out, 'logits') else out\n            pred = out.max(1)[1].item()\n            if pred != y[idx].item():\n                break\n            model.zero_grad()\n            out[0, pred].backward(retain_graph=True)\n            grad_pred = pert.grad.data.clone()\n            min_dist, min_grad = 1e10, None\n            for k in range(out.size(1)):\n                if k == pred:\n                    continue\n                model.zero_grad()\n                pert.grad = None\n                try:\n                    out[0, k].backward(retain_graph=True)\n                    grad_k = pert.grad.data.clone()\n                    w_k = grad_k - grad_pred\n                    f_k = out[0, k] - out[0, pred]\n                    dist = abs(f_k.item()) / (torch.norm(w_k.flatten()).item() + 1e-8)\n                    if dist < min_dist:\n                        min_dist, min_grad = dist, w_k\n                except:\n                    continue\n            if min_grad is not None:\n                r = (min_dist + 1e-4) * min_grad / (torch.norm(min_grad.flatten()) + 1e-8)\n                pert = torch.clamp(pert.detach() + 1.02 * r, -1, 1)\n            else:\n                break\n        perturbed[idx:idx+1] = pert.detach()\n    return perturbed\n\n# Load data\nprint(f\"\\n{'='*70}\")\nprint(\" LOADING DATA\")\nprint('='*70)\nconfig = DATASET_CONFIGS[DATASET_NAME.lower()]\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.Grayscale(num_output_channels=3),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n])\ntest_dataset = config['class'](root='./data/medmnist', split='test', download=True, transform=transform)\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\nprint(f\"✅ Loaded {len(test_dataset)} test samples | Classes: {config['num_classes']}\")\n\n# Load model\nprint(f\"\\n{'='*70}\")\nprint(\" LOADING MODEL\")\nprint('='*70)\nmodel = CLIPMedMNISTClassifier(config['num_classes'], device, config['class_names'])\ncheckpoint = torch.load(MODEL_PATH, map_location=device)\nif isinstance(checkpoint, dict):\n    if 'server_state_dict' in checkpoint:\n        model.load_state_dict(checkpoint['server_state_dict'])\n    elif 'model_state_dict' in checkpoint:\n        model.load_state_dict(checkpoint['model_state_dict'])\n    else:\n        model.load_state_dict(checkpoint)\nelse:\n    model.load_state_dict(checkpoint)\nmodel.eval()\nprint(\"✅ Model loaded successfully\")\n\n# Run attacks\nprint(f\"\\n{'='*70}\")\nprint(\" RUNNING 5 ATTACKS\")\nprint('='*70)\n\nattacks = {\n    'FGSM': lambda x, y: fgsm(model, x, y, device),\n    'PGD': lambda x, y: pgd(model, x, y, device),\n    'BIM': lambda x, y: bim(model, x, y, device),\n    'MI-FGSM': lambda x, y: mifgsm(model, x, y, device),\n    'DeepFool': lambda x, y: deepfool(model, x, y, device)\n}\n\nresults = []\nfor name, attack_fn in attacks.items():\n    print(f\"\\n[{name}]\")\n    clean_c, adv_c, total = 0, 0, 0\n    for imgs, lbls in tqdm(test_loader, desc=f\"  {name:12s}\", ncols=100, leave=False):\n        imgs, lbls = imgs.to(device), lbls.to(device).squeeze()\n        with torch.no_grad():\n            out = model(imgs)\n            clean_c += (out.max(1)[1] == lbls).sum().item()\n        try:\n            adv = attack_fn(imgs, lbls)\n            with torch.no_grad():\n                out = model(adv)\n                adv_c += (out.max(1)[1] == lbls).sum().item()\n        except:\n            adv_c += imgs.size(0)\n        total += lbls.size(0)\n    \n    clean_acc = 100 * clean_c / total\n    adv_acc = 100 * adv_c / total\n    asr = 100 * (clean_c - adv_c) / clean_c if clean_c > 0 else 0\n    print(f\"  ✅ Clean: {clean_acc:.2f}% | Adv: {adv_acc:.2f}% | ASR: {asr:.2f}%\")\n    results.append({'attack': name, 'clean_accuracy': round(clean_acc, 2),\n                    'adversarial_accuracy': round(adv_acc, 2), 'attack_success_rate': round(asr, 2)})\n\n# Save & plot\nwith open(f\"{SAVE_DIR}/attack_results.json\", 'w') as f:\n    json.dump(results, f, indent=2)\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\nnames = [r['attack'] for r in results]\nclean = [r['clean_accuracy'] for r in results]\nadv = [r['adversarial_accuracy'] for r in results]\nasr = [r['attack_success_rate'] for r in results]\nx = np.arange(len(names))\nax1.bar(x - 0.175, clean, 0.35, label='Clean', alpha=0.8, color='#2ecc71')\nax1.bar(x + 0.175, adv, 0.35, label='Adversarial', alpha=0.8, color='#e74c3c')\nax1.set_xlabel('Attack'); ax1.set_ylabel('Accuracy (%)')\nax1.set_title('Robustness', fontweight='bold'); ax1.set_xticks(x)\nax1.set_xticklabels(names, rotation=15); ax1.legend(); ax1.grid(alpha=0.3, axis='y')\nax2.bar(names, asr, color=['#e74c3c', '#e67e22', '#f39c12', '#d35400', '#c0392b'], alpha=0.8)\nax2.set_xlabel('Attack'); ax2.set_ylabel('ASR (%)')\nax2.set_title('Attack Effectiveness', fontweight='bold'); ax2.set_xticklabels(names, rotation=15)\nax2.grid(alpha=0.3, axis='y')\nplt.tight_layout()\nplt.savefig(f\"{SAVE_DIR}/attack_results.png\", dpi=300, bbox_inches='tight')\nplt.close()\n\nprint(f\"\\n{'='*70}\")\nprint(\" COMPLETE!\")\nprint('='*70)\nprint(f\"✅ JSON: {SAVE_DIR}/attack_results.json\")\nprint(f\"✅ Plot: {SAVE_DIR}/attack_results.png\")\nfor r in results:\n    print(f\"  {r['attack']:10s} | Clean: {r['clean_accuracy']:5.2f}% | Adv: {r['adversarial_accuracy']:5.2f}% | ASR: {r['attack_success_rate']:5.2f}%\")\nprint('='*70)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T01:48:06.095060Z","iopub.execute_input":"2025-12-03T01:48:06.095414Z"}},"outputs":[{"name":"stdout","text":"Installing dependencies...\n✅ All dependencies loaded!\n\n======================================================================\n LOADING DATA\n======================================================================\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 38.2M/38.2M [00:41<00:00, 927kB/s] \n","output_type":"stream"},{"name":"stdout","text":"✅ Loaded 17778 test samples | Classes: 11\n\n======================================================================\n LOADING MODEL\n======================================================================\n","output_type":"stream"},{"name":"stderr","text":"100%|████████████████████████████████████████| 338M/338M [00:01<00:00, 262MiB/s]\n","output_type":"stream"},{"name":"stdout","text":"✅ Model loaded successfully\n\n======================================================================\n RUNNING 5 ATTACKS\n======================================================================\n\n[FGSM]\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                    \r","output_type":"stream"},{"name":"stdout","text":"  ✅ Clean: 90.12% | Adv: 56.25% | ASR: 37.59%\n\n[PGD]\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                    \r","output_type":"stream"},{"name":"stdout","text":"  ✅ Clean: 90.12% | Adv: 45.18% | ASR: 49.87%\n\n[BIM]\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                    \r","output_type":"stream"},{"name":"stdout","text":"  ✅ Clean: 90.12% | Adv: 44.76% | ASR: 50.34%\n\n[MI-FGSM]\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                    \r","output_type":"stream"},{"name":"stdout","text":"  ✅ Clean: 90.12% | Adv: 44.80% | ASR: 50.29%\n\n[DeepFool]\n","output_type":"stream"},{"name":"stderr","text":"  DeepFool    :   1%|▋                                            | 8/556 [02:19<2:28:55, 16.31s/it]","output_type":"stream"}],"execution_count":null}]}